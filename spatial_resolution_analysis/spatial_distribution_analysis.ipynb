{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping RNAscope & Spatial-Transcriptomics Data to a Calibrated Vestibular-Ganglion Reference Frame  \n",
    "*Author:* &lt;Ruiqi Liu&gt;  \n",
    "*Date:* 2025-09-10\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Purpose  \n",
    "This notebook performs **end-to-end coordinate mapping** of RNA-scope or ST spot data onto a **standardised, calibrated Vestibular Ganglion (VG)** atlas.  \n",
    "\n",
    "### Three core stages  \n",
    "1. Build the **standard VG frame**  \n",
    "2. **Map every slice** into that frame  \n",
    "3. **Summarise, visualise & analyse** spatial gene-expression patterns  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Construction of the Standardised VG Reference Frame  \n",
    "- Import **all VG slices**, together with manually drawn **landmark points** outlining the boundary anatomical features.  \n",
    "- Perform **size normalisation** on each slice based on these landmarks, then compute the **pixel-wise average** across the entire set to establish the final VG common reference frame.  \n",
    "- Use **Thin-Plate-Spline (TPS)** warping to align every normalised slice to this average frame, generating an **average template** and a **surface mesh** that remain unchanged for downstream mapping steps.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import os\n",
    "from modules import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path and parameters\n",
    "base_folder = 'path/to/your/data/'\n",
    "landmarks_folder = os.path.join(base_folder, 'landmarks')\n",
    "summary_folder = os.path.join(base_folder, 'summary')\n",
    "data_folder = os.path.join(base_folder, 'data')\n",
    "\n",
    "# list of markers and landmarkpoints\n",
    "marker_list = ['a', 'b', 'c', 'd', 'e']\n",
    "point_label_list = ['big sharp', 'big flat', 'mid sharp', 'mid flat', 'small sharp', 'small flat', 'small2mid', 'big2mid']\n",
    "order_list = [0, 7, 2, 6, 4, 5, 3, 1, 0]\n",
    "\n",
    "# retrieve data subfolders\n",
    "sub_folders = [f for f in os.listdir(data_folder) \n",
    "               if os.path.isdir(os.path.join(data_folder, f)) and f not in ['.', '..']]\n",
    "\n",
    "print(f'Root Directory: {base_folder}')\n",
    "print(f'Total number of samples: {len(sub_folders)}')\n",
    "print(f'Sample List: {sub_folders}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "print('===== Step 1: Data Preprocessing =====')\n",
    "try:\n",
    "    preprocessing.preprocessing(base_folder, landmarks_folder, data_folder)\n",
    "    print('‚úÖ Step 1: Data Preprocessing')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Step 1: Data Preprocessing Failed: {e}')\n",
    "\n",
    "# Step 2: Calculate the standardized coordinates for each sample\n",
    "print('===== Step 2: Calculate the standardized coordinates for each sample =====')\n",
    "try:\n",
    "    preprocessing.norm_rot_point(data_folder, summary_folder, sub_folders)\n",
    "    print('‚úÖ Step 2: Calculate the standardized coordinates for each sample')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Step 2: Calculate the standardized coordinates for each sample Failed: {e}')\n",
    "\n",
    "# Step 3: Draw the average VG\n",
    "print('===== Step 3: Draw the average VG =====')\n",
    "try:\n",
    "    preprocessing.registration_to_frame(data_folder, summary_folder, sub_folders, point_label_list, order_list)\n",
    "    print('‚úÖ Step 3: Draw the average VG')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Step 3: Draw the average VG Failed: {e}')\n",
    "\n",
    "# Step 4: Generate the landmarks table\n",
    "print('===== Step 4: Generate the landmarks table =====')\n",
    "try:\n",
    "    preprocessing.mapping_landmarks(data_folder, summary_folder, sub_folders)\n",
    "    print('‚úÖ Step 4: Generate the landmarks table')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Step 4: Generate the landmarks table Failed: {e}')\n",
    "\n",
    "# Step 5: Generate the original coordinates of the ROI\n",
    "print('===== Step 5: Generate the original coordinates of the ROI =====')\n",
    "try:\n",
    "    preprocessing.true_mapping_roi(marker_list, data_folder, sub_folders)\n",
    "    print('‚úÖ Step 5: Generate the original coordinates of the ROI')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Step 5: Generate the original coordinates of the ROI Failed: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Slice-to-Atlas Mapping  \n",
    "‚ùóBefore running this step, you need to run Script.groovy to generate a calibrated list of cell coordinates.\n",
    "- Load spot tables (`gene, x, y`) and gene matrices  \n",
    "- Calibrate transform with **fiduciary landmarks**  \n",
    "  - ganglion contours  \n",
    "- Apply **thin-plate-spline** transform  \n",
    "- QC: overlay mapped slice on reference outline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules\n",
    "import os\n",
    "from modules import roi_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path and parameters\n",
    "base_folder = 'path/to/your/data/'\n",
    "summary_folder = os.path.join(base_folder, 'summary')\n",
    "data_folder = os.path.join(base_folder, 'data')\n",
    "sub_folders = [f for f in os.listdir(data_folder) \n",
    "               if os.path.isdir(os.path.join(data_folder, f)) and f not in ['.', '..']]\n",
    "marker_names = ['a', 'b', 'c', 'd', 'e']\n",
    "order_list = [0, 7, 2, 6, 4, 5, 3, 1, 0]\n",
    "\n",
    "print(f'Root Directory: {base_folder}')\n",
    "print(f'Total number of samples: {len(sub_folders)}')\n",
    "print(f'Sample List: {sub_folders}')\n",
    "print(f'Marker List: {marker_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Draw the ROI map for each sample\n",
    "print('===== Step 1: Draw the ROI map for each sample =====')\n",
    "roi_distribution.plot_individually(summary_folder, sub_folders, data_folder)\n",
    "print('‚úÖ Step 1: Draw the ROI map for each sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Summarize the ROI information for each subtype\n",
    "print('===== Step 2: Summarize the ROI information for each subtype =====')\n",
    "roi_distribution.summary_subtypes_csv(summary_folder, data_folder)\n",
    "print('‚úÖ Step 2: Summarize the ROI information for each subtypeÔºâ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Draw the ROI scatter and distribution plots for each subtype\n",
    "print('===== Step 3: Draw the ROI scatter and distribution plots for each subtype =====')\n",
    "try:\n",
    "    num_xbins = 20\n",
    "    num_ybins = 10\n",
    "    roi_distribution.plot_summary_scatter(summary_folder, marker_names, order_list, num_xbins, num_ybins)\n",
    "    print('‚úÖ Step 3: Draw the ROI scatter and distribution plots for each subtype')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Step 3: Draw the ROI scatter and distribution plots for each subtype Failed: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "sample_info_path = os.path.join(summary_folder, \"sample_info.csv\")\n",
    "# Read sample_info.csv to obtain samName\n",
    "try:\n",
    "    sample_info_df = pd.read_csv(sample_info_path)\n",
    "    # Get unique list of samName\n",
    "    sam_names = sample_info_df['sam_name'].unique()\n",
    "    print(f'‚úÖ Successfully read sample info file, found {len(sam_names)} unique sam_name(s)')\n",
    "    print(f'sam_name list: {list(sam_names)}')\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: file not found {sample_info_path}\")\n",
    "    print(\"Please check if the file path is correct\")\n",
    "    sam_names = []\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error while reading file: {e}\")\n",
    "    sam_names = []\n",
    "\n",
    "# Inspect files in the summary folder\n",
    "if os.path.exists(summary_folder):\n",
    "    summary_files = os.listdir(summary_folder)\n",
    "    csv_files = [f for f in summary_files if f.endswith('.csv')]\n",
    "    print(f'{len(csv_files)} CSV file(s) found in summary folder')\n",
    "    print('First 10 CSV files:')\n",
    "    for i, file in enumerate(csv_files[:10]):\n",
    "        print(f'  {i+1}. {file}')\n",
    "    if len(csv_files) > 10:\n",
    "        print(f'  ... and {len(csv_files) - 10} more files')\n",
    "else:\n",
    "    print(f'‚ùå Summary folder does not exist: {summary_folder}')\n",
    "\n",
    "\n",
    "def process_sam_name(sam_name, summary_folder):\n",
    "    \"\"\"Merge data for a single sam_name\"\"\"\n",
    "    print(f\"\\nProcessing sam_name: {sam_name}\")\n",
    "\n",
    "    # Find all summary files for current samName, excluding files ending with _all.csv\n",
    "    sam_files = [f for f in os.listdir(summary_folder)\n",
    "                 if f.startswith(f\"{sam_name}_summary_\") and not f.endswith(\"_all.csv\")]\n",
    "\n",
    "    if not sam_files:\n",
    "        print(f\"‚ö†Ô∏è Warning: no files found for sam_name {sam_name}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"{len(sam_files)} related file(s) found:\")\n",
    "    for file in sam_files:\n",
    "        print(f\"  - {file}\")\n",
    "\n",
    "    # List to store dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Read each file\n",
    "    for file in sam_files:\n",
    "        file_path = os.path.join(summary_folder, file)\n",
    "        try:\n",
    "            # Extract marker name from filename\n",
    "            parts = file.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                marker = parts[2].replace('.csv', '')\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Warning: filename format unexpected {file}, skip marker extraction.\")\n",
    "                marker = \"\"\n",
    "\n",
    "            # Read CSV\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Ensure Label column exists\n",
    "            if 'Label' not in df.columns:\n",
    "                print(f\"‚ö†Ô∏è Warning: no Label column in {file_path}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Add marker prefix to all columns except Label (if marker exists)\n",
    "            if marker:\n",
    "                rename_dict = {col: f\"{marker}_{col}\" for col in df.columns if col != 'Label'}\n",
    "                df = df.rename(columns=rename_dict)\n",
    "                print(f\"    Added marker prefix '{marker}' for {file}\")\n",
    "\n",
    "            dataframes.append(df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading file {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not dataframes:\n",
    "        print(f\"‚ùå No valid data found for sam_name: {sam_name}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"Successfully read {len(dataframes)} data file(s)\")\n",
    "\n",
    "    # Horizontally merge all dataframes on Label using reduce\n",
    "    if len(dataframes) > 1:\n",
    "        final_df = reduce(\n",
    "            lambda left, right: pd.merge(left, right, on='Label', how='outer'),\n",
    "            dataframes\n",
    "        )\n",
    "        print(f\"Merge completed, final dataframe shape: {final_df.shape}\")\n",
    "    else:\n",
    "        final_df = dataframes[0]\n",
    "        print(f\"Only one dataframe, no merge needed, shape: {final_df.shape}\")\n",
    "\n",
    "    # Handle missing values differently for isPositive columns vs others\n",
    "    # Get all isPositive columns\n",
    "    is_positive_cols = [col for col in final_df.columns if col.endswith('_isPositive')]\n",
    "    # Other columns (excluding Label and isPositive)\n",
    "    other_cols = [col for col in final_df.columns if col not in is_positive_cols and col != 'Label']\n",
    "\n",
    "    # Fill missing values in isPositive columns with 0\n",
    "    if is_positive_cols:\n",
    "        final_df[is_positive_cols] = final_df[is_positive_cols].fillna(0)\n",
    "        print(f\"Filled missing values with 0 for {len(is_positive_cols)} isPositive column(s)\")\n",
    "\n",
    "    # Fill missing values in other columns with -1\n",
    "    if other_cols:\n",
    "        final_df[other_cols] = final_df[other_cols].fillna(-1)\n",
    "        print(f\"Filled missing values with -1 for {len(other_cols)} other column(s)\")\n",
    "\n",
    "    # Add hasPositive column\n",
    "    if is_positive_cols:\n",
    "        print(f\"Found {len(is_positive_cols)} isPositive column(s): {is_positive_cols}\")\n",
    "        # Ensure numeric type for calculation\n",
    "        for col in is_positive_cols:\n",
    "            if col in final_df.columns:\n",
    "                final_df[col] = pd.to_numeric(final_df[col], errors='coerce').fillna(0)\n",
    "\n",
    "        # hasPositive = 1 if any isPositive column equals 1, else 0\n",
    "        final_df['hasPositive'] = final_df[is_positive_cols].apply(\n",
    "            lambda row: 1 if (row == 1).any() else 0, axis=1\n",
    "        )\n",
    "        print(\"hasPositive column calculated\")\n",
    "    else:\n",
    "        final_df['hasPositive'] = 0\n",
    "        print(\"No isPositive columns found, hasPositive set to all zeros\")\n",
    "\n",
    "    # Remove fully duplicate rows before saving\n",
    "    original_rows = len(final_df)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "    removed_rows = original_rows - len(final_df)\n",
    "    if removed_rows > 0:\n",
    "        print(f\"Removed {removed_rows} duplicate row(s)\")\n",
    "\n",
    "    # Save merged dataframe\n",
    "    output_file_name = f\"{sam_name}_summary_all.csv\"\n",
    "    output_file_path = os.path.join(summary_folder, output_file_name)\n",
    "    final_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"‚úÖ Summary table saved to {output_file_path}\")\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "print(\"Processing function defined!\")\n",
    "# Run data processing\n",
    "if len(sam_names) > 0:\n",
    "    print(\"===== Start processing data for all sam_name =====\")\n",
    "\n",
    "    success_count = 0\n",
    "    for sam_name in sam_names:\n",
    "        if process_sam_name(sam_name, summary_folder):\n",
    "            success_count += 1\n",
    "\n",
    "    print(f\"\\nüéâ All sam_name data processing complete!\")\n",
    "    print(f\"Successfully processed: {success_count}/{len(sam_names)} sam_name(s)\")\n",
    "else:\n",
    "    print(\"‚ùå No sam_name found, cannot proceed\")\n",
    "\n",
    "# Inspect generated files\n",
    "print(\"\\n===== Inspect generated files =====\")\n",
    "if os.path.exists(summary_folder):\n",
    "    all_files = [f for f in os.listdir(summary_folder) if f.endswith('_all.csv')]\n",
    "    if all_files:\n",
    "        print(f\"Found {len(all_files)} summary file(s):\")\n",
    "        for file in all_files:\n",
    "            file_path = os.path.join(summary_folder, file)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"  - {file} ({file_size} bytes)\")\n",
    "\n",
    "            # Preview file content\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                print(f\"    Shape: {df.shape}, Columns: {len(df.columns)}\")\n",
    "                print(f\"    Column names: {list(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    Unable to read file content: {e}\")\n",
    "    else:\n",
    "        print(\"No summary files found\")\n",
    "else:\n",
    "    print(f\"Summary folder does not exist: {summary_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Summarisation, Visualisation & Significance Testing  \n",
    "- Aggregate counts into **grid maps**  \n",
    "- Create **2-D surface** and **1-D flattened** expression maps  \n",
    "- Run  \n",
    "  - differential expression  \n",
    "- Export  \n",
    "  - publication-ready PNG/SVG  \n",
    "  - CSV of p-values & effect sizes  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one sample mode, each marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "from modules.judge_sig import (\n",
    "    create_position_bins,\n",
    "    two_step_stratified_sample,\n",
    "    monte_carlo_simulation,\n",
    "    x_monte,\n",
    "    correct_grid_pvalues,\n",
    "    plot_corrected_p_heatmap,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_simulations = 10000\n",
    "num_xbins = 20\n",
    "num_ybins = 10\n",
    "correction_method = 'fdr'\n",
    "bx_min = -0.6\n",
    "bx_max = 0.6\n",
    "by_min = -0.6\n",
    "by_max = 0.6\n",
    "\n",
    "cell_num = 0\n",
    "random_num =42\n",
    "\n",
    "sample_type = 'wt'\n",
    "# ----------------------\n",
    "# paths\n",
    "# ----------------------\n",
    "base_folder = 'path/to/your/data/' \n",
    "summary_folder = os.path.join(base_folder, \"summary\")\n",
    "sample_info_path = os.path.join(summary_folder, \"sample_info.csv\")\n",
    "wt_summary_path = os.path.join(summary_folder, sample_type + \"_summary_all.csv\")\n",
    "results_file_path = os.path.join(summary_folder, 'vg_averageing_labels.csv')\n",
    "vg_size_path = os.path.join(summary_folder, 'vg_size.csv')\n",
    "\n",
    "print(f'Root directory: {base_folder}')\n",
    "print(f'Summary folder: {summary_folder}')\n",
    "print(f'Number of simulations: {n_simulations}')\n",
    "print(f'Number of x-bins: {num_xbins}, Number of y-bins: {num_ybins}')\n",
    "print(f'Correction method: {correction_method}')\n",
    "\n",
    "# ----------------------\n",
    "# load the data and preprocessing\n",
    "# ----------------------\n",
    "def load_data():\n",
    "    try:\n",
    "        wt_data = pd.read_csv(wt_summary_path)\n",
    "        print(f\"succesfullly load {sample_type} data, length : {len(wt_data)} rows\")\n",
    "        \n",
    "        results_data = pd.read_csv(results_file_path, header=None)\n",
    "        BX = results_data.iloc[:, 0].values\n",
    "        BY = results_data.iloc[:, 1].values\n",
    "        print(f\"succesfully load BX/BY, length are : {len(BX)}, {len(BY)}\")\n",
    "        \n",
    "        return wt_data, BX, BY\n",
    "    except Exception as e:\n",
    "        print(f\"data loading error: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "summary_data, BX, BY = load_data()\n",
    "original_count = len(summary_data)\n",
    "summary_data = summary_data.drop_duplicates(keep='first')\n",
    "deduplicated_count = len(summary_data)\n",
    "removed_count = original_count - deduplicated_count\n",
    "print(f\"data num: {deduplicated_count} (removed {removed_count} duplicates\")\n",
    "\n",
    "# Read VG size data and calculate normalized coordinates\n",
    "vg_size = pd.read_csv(vg_size_path, header=None)\n",
    "avg_vg_size = vg_size.mean(axis=0).values\n",
    "print(f\"VG average size: {avg_vg_size}\")\n",
    "\n",
    "\n",
    "is_positive_cols = [col for col in summary_data.columns if col.endswith('_isPositive')]\n",
    "if not is_positive_cols:\n",
    "    raise ValueError(\"No columns ending with '_isPositive' were found, please check the column names.\")\n",
    "print(f\"find {len(is_positive_cols)} positive-labeling columns: {is_positive_cols}\")\n",
    "\n",
    "# Find coordinate column\n",
    "x_col = next((col for col in summary_data.columns if col.endswith('warpedROIvar1')), None)\n",
    "y_col = next((col for col in summary_data.columns if col.endswith('warpedROIvar2')), None)\n",
    "\n",
    "if not x_col or not y_col:\n",
    "    missing = []\n",
    "    if not x_col: missing.append(\"The column ending with warpedROIvar1\")\n",
    "    if not y_col: missing.append(\"The column ending with warpedROIvar2\")\n",
    "    raise ValueError(f\"necessary cols lost: {', '.join(missing)}\")\n",
    "\n",
    "# Calculate standardized coordinates\n",
    "summary_data['standardized_x'] = summary_data[x_col] / avg_vg_size[0]\n",
    "summary_data['standardized_y'] = summary_data[y_col] / avg_vg_size[1]\n",
    "\n",
    "data = summary_data[['Label'] + is_positive_cols + ['standardized_x', 'standardized_y', 'hasPositive']].copy()\n",
    "\n",
    "if cell_num > 0 :\n",
    "    data = two_step_stratified_sample(data, cell_num, random_num)\n",
    "\n",
    "order_list=[0, 7, 2, 6, 4, 5, 3, 1, 0]\n",
    "BX_ordered = BX[order_list]\n",
    "BY_ordered = BY[order_list]\n",
    "cs = CubicSpline(np.arange(len(BX_ordered)), np.c_[BX_ordered, BY_ordered], \n",
    "                axis=0, bc_type='periodic')\n",
    "t_fine = np.linspace(0, len(BX_ordered)-1, 300)\n",
    "x_fine, y_fine = cs(t_fine).T\n",
    "\n",
    "# Calculate the boundaries of BX and BY\n",
    "actual_bx_min, actual_bx_max = x_fine.min(), x_fine.max()\n",
    "actual_by_min, actual_by_max = y_fine.min(), y_fine.max()\n",
    "\n",
    "# Create Intervals\n",
    "bx_bins, by_bins = create_position_bins(\n",
    "    actual_bx_min, actual_bx_max,\n",
    "    actual_by_min, actual_by_max,\n",
    "    num_xbins, num_ybins\n",
    ")\n",
    "\n",
    "print(f\"BX: from {actual_bx_min:.2f} to {actual_bx_max:.2f}\")\n",
    "print(f\"BY: from {actual_by_min:.2f} to {actual_by_max:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Starting Monte Carlo simulation =====\")\n",
    "results = []\n",
    "\n",
    "for col in is_positive_cols:\n",
    "    gene = col.replace('_isPositive', '')\n",
    "    x_col = 'standardized_x'\n",
    "    y_col = 'standardized_y'\n",
    "    \n",
    "    if x_col not in data.columns or y_col not in data.columns:\n",
    "        print(f\"‚ö†Ô∏è Warning: standardized coordinate columns not found, skipping {col}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n===== Analyzing {col} =====\")\n",
    "    print(f\"Coordinate columns used: X={x_col}, Y={y_col}\")\n",
    "    \n",
    "    result = monte_carlo_simulation(data, col, x_col, y_col, bx_bins, by_bins, n_simulations, save_base_dir=os.path.join(summary_folder, \"test_monte\"))\n",
    "    \n",
    "    if result is not None:\n",
    "        total_real = np.sum(result['real_counts'])\n",
    "        print(f\"Total real counts for {col}: {total_real}\")\n",
    "        \n",
    "        if total_real > 0:\n",
    "            result['corrected_p'] = correct_grid_pvalues(result['p_values'], method=correction_method)\n",
    "            results.append(result)\n",
    "            print(f\"‚úÖ Analysis of {col} completed\")\n",
    "        else:\n",
    "            print(f\"‚ùå Total real counts for {col} is 0, not adding to results\")\n",
    "    else:\n",
    "        print(f\"‚ùå Analysis of {col} failed, no result generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 0\n",
    "max_count = 0.02\n",
    "if results:\n",
    "    print(\"\\n===== Saving analysis results =====\")\n",
    "    if cell_num > 0:\n",
    "        results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_{cell_num}\")\n",
    "        visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_{cell_num}\")\n",
    "    else:\n",
    "        results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}\")\n",
    "        visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "    for result in results:\n",
    "        gene = result['gene']\n",
    "        np.savetxt(os.path.join(results_folder, f'{gene}_real_counts.csv'), result['real_counts'], delimiter=',', fmt='%d')\n",
    "        np.savetxt(os.path.join(results_folder, f'{gene}_corrected_p.csv'), result['corrected_p'], delimiter=',', fmt='%.6f')\n",
    "        plot_corrected_p_heatmap(result, data, gene, bx_min, bx_max, by_min, by_max, BX, BY, visualization_folder, min_count, max_count)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No valid results were generated\")\n",
    "\n",
    "print(\"\\n===== Analysis complete =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n===== Starting x-axis distribution Monte Carlo simulation =====\")\n",
    "results = []\n",
    "\n",
    "for col in is_positive_cols:\n",
    "    gene = col.replace('_isPositive', '')\n",
    "    x_col = 'standardized_x'\n",
    "    y_col = 'standardized_y'\n",
    "    \n",
    "    if x_col not in data.columns or y_col not in data.columns:\n",
    "        print(f\"‚ö†Ô∏è Warning: standardized coordinate columns not found, skipping {col}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n===== Analyzing {col} =====\")\n",
    "    print(f\"Coordinate columns used: X={x_col}, Y={y_col}\")\n",
    "    \n",
    "    result = x_monte(\n",
    "        data, col, x_col, \n",
    "        bx_bins, n_simulations\n",
    "    )\n",
    "    \n",
    "    if result is not None:\n",
    "        total_real = np.sum(result['real_counts'])\n",
    "        print(f\"Total real counts for {col}: {total_real}\")\n",
    "        \n",
    "        if total_real > 0:\n",
    "            result['corrected_p'] = correct_grid_pvalues(result['p_values'], method=correction_method)\n",
    "            results.append(result)\n",
    "            print(f\"‚úÖ Analysis of {col} completed\")\n",
    "        else:\n",
    "            print(f\"‚ùå Total real counts for {col} is 0, not adding to results\")\n",
    "    else:\n",
    "        print(f\"‚ùå Analysis of {col} failed, no result generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 0\n",
    "max_count = 0.1\n",
    "p_value_threshold = 0.05  # significance threshold\n",
    "# -------------------------- Key: define target Marker order --------------------------\n",
    "target_marker_order = ['a', 'b', 'c', 'd', 'e']  # top-to-bottom order\n",
    "\n",
    "if results:\n",
    "    print(\"\\n===== 1. Merge and save X-axis data for all Markers =====\")\n",
    "    # 1.1 Create folder with _xbins suffix (following previous path rule)\n",
    "    if cell_num > 0:\n",
    "        results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_{cell_num}_xbins\")\n",
    "        visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_{cell_num}_xbins\")\n",
    "    else:\n",
    "        results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_xbins\")\n",
    "        visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_xbins\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "    os.makedirs(visualization_folder, exist_ok=True)\n",
    "\n",
    "    # 1.2 Extract X-axis bin edges (all markers share the same x bins; use first valid result's logic)\n",
    "    x_bin_edges = np.linspace(BX.min(), BX.max(), num_xbins + 1)  # original X-axis bin boundaries\n",
    "    x_bin_labels = [f\"Bin{i+1}\\n[{x_bin_edges[i]:.2f}-{x_bin_edges[i+1]:.2f}]\" for i in range(len(x_bin_edges) - 1)]\n",
    "    x_bin_num = len(x_bin_labels)  # total number of X bins\n",
    "\n",
    "    # 1.3 Merge real_counts and corrected_p for all markers\n",
    "    # Initialise merged DataFrame (rows = markers, columns = x bins)\n",
    "    marker_list = []\n",
    "    real_counts_all = []\n",
    "    corrected_p_all = []\n",
    "\n",
    "    # ---------- 1. Compute 20 bin indices ----------\n",
    "    min_bin_idx = np.digitize(x_fine.min(), bx_bins) - 1\n",
    "    max_bin_idx = np.digitize(x_fine.max(), bx_bins) - 1\n",
    "    zero_bin_idx = np.digitize(0, bx_bins) - 1\n",
    "    x_bins_indices = np.arange(min_bin_idx, min_bin_idx + 20)  # fixed 20 bins\n",
    "    x_offsets = x_bins_indices - zero_bin_idx  # offset relative to 0\n",
    "\n",
    "    # ---------- 2. Pick ticks every 5 steps, centred at 0, only within existing 20 offsets ----------\n",
    "    step = 5\n",
    "    low = int(np.floor(x_offsets.min() / step) * step)\n",
    "    high = int(np.ceil(x_offsets.max() / step) * step)\n",
    "    tick_labels = np.arange(low, high + 1, step)  # multiples of 5\n",
    "    tick_labels = tick_labels[np.isin(tick_labels, x_offsets)]  # ensure existence\n",
    "\n",
    "    # ---------- 3. Corresponding plot positions ----------\n",
    "    tick_positions = [np.where(x_offsets == lab)[0][0] for lab in tick_labels]\n",
    "\n",
    "    for result in results:\n",
    "        marker = result['gene']\n",
    "        rc = result['real_counts']  # 1-D array (number of x bins)\n",
    "        cp = result['corrected_p']  # 1-D array (number of x bins)\n",
    "\n",
    "        rc = rc[min_bin_idx:max_bin_idx]\n",
    "        cp = cp[min_bin_idx:max_bin_idx]\n",
    "        marker_list.append(marker)\n",
    "        real_counts_all.append(rc)\n",
    "        corrected_p_all.append(cp)\n",
    "\n",
    "    # 1.4 Save merged data (CSV format for downstream use)\n",
    "    # Save real counts (marker √ó x bin)\n",
    "    rc_df = pd.DataFrame(real_counts_all, index=marker_list, columns=[f\"X_Bin{i+1}\" for i in range(num_xbins)])\n",
    "    rc_df.index.name = \"Marker\"\n",
    "    rc_df.to_csv(os.path.join(results_folder, \"all_markers_real_counts.csv\"), index=True)\n",
    "    print(f\"‚úÖ Saved real counts for all markers: all_markers_real_counts.csv\")\n",
    "\n",
    "    # Save corrected p values (marker √ó x bin)\n",
    "    cp_df = pd.DataFrame(corrected_p_all, index=marker_list, columns=[f\"X_Bin{i+1}\" for i in range(num_xbins)])\n",
    "    cp_df.index.name = \"Marker\"\n",
    "    cp_df.to_csv(os.path.join(results_folder, \"all_markers_corrected_p.csv\"), index=True)\n",
    "    print(f\"‚úÖ Saved corrected p values for all markers: all_markers_corrected_p.csv\")\n",
    "\n",
    "    # Save X-axis bin info (for plotting / interpretation)\n",
    "    x_bin_info = pd.DataFrame({\n",
    "        \"Bin_Index\": range(1, num_xbins + 1),\n",
    "        \"Bin_Left\": BX.min(),\n",
    "        \"Bin_Right\": BX.max()\n",
    "    })\n",
    "    x_bin_info.to_csv(os.path.join(results_folder, \"x_axis_bin_info.csv\"), index=False)\n",
    "    print(f\"‚úÖ Saved X-axis bin info: x_axis_bin_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 0\n",
    "max_count = 0.1\n",
    "p_value_threshold = 0.05  # significance threshold\n",
    "# -------------------------- Key: define target Marker order --------------------------\n",
    "target_marker_order = ['a', 'b', 'c', 'd', 'e']  # top-to-bottom order\n",
    "\n",
    "if cell_num > 0:\n",
    "    results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_{cell_num}_xbins\")\n",
    "    visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_{cell_num}_xbins\")\n",
    "else:\n",
    "    results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_xbins\")\n",
    "    visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_xbins\")\n",
    "\n",
    "if results:\n",
    "    rc_df = pd.read_csv(os.path.join(results_folder, \"all_markers_real_counts.csv\"), header=0, index_col=0)\n",
    "    cp_df = pd.read_csv(os.path.join(results_folder, \"all_markers_corrected_p.csv\"), header=0, index_col=0)\n",
    "    x_bin_info = pd.read_csv(os.path.join(results_folder, \"x_axis_bin_info.csv\"), header=0, index_col=0)\n",
    "    # -------------------------- 2. Plot integrated heatmap (all markers combined) --------------------------\n",
    "    print(\"\\n===== 2. Plot integrated heatmap for all Markers =====\")\n",
    "    # -------------------------- Key modification 1: filter and reorder data by target order --------------------------\n",
    "    # 1. Filter: keep only target Markers\n",
    "    rc_df_filtered = rc_df.loc[rc_df.index.isin(target_marker_order)]  # count data filter\n",
    "    cp_df_filtered = cp_df.loc[cp_df.index.isin(target_marker_order)]  # p-value data filter\n",
    "\n",
    "    # 2. Reorder: adjust row index according to target_marker_order (core step)\n",
    "    rc_df_ordered = rc_df_filtered.reindex(target_marker_order)  # count data in target order\n",
    "    cp_df_ordered = cp_df_filtered.reindex(target_marker_order)  # p-value data in target order\n",
    "\n",
    "    # 3. Check for missing data (optional: avoid empty plot if target Marker absent)\n",
    "    missing_markers = [m for m in target_marker_order if m not in rc_df_ordered.index]\n",
    "    if missing_markers:\n",
    "        print(f\"‚ö†Ô∏è No data for following Marker(s), skipped: {missing_markers}\")\n",
    "    if rc_df_ordered.empty:\n",
    "        print(\"‚ö†Ô∏è No valid Marker data, skipping plot\")\n",
    "    else:\n",
    "        # 2.1 Data preprocessing (based on reordered data)\n",
    "        rc_normalized = rc_df_ordered.div(rc_df_ordered.sum(axis=1), axis=0)  # normalize counts\n",
    "        cp_clipped = cp_df_ordered.clip(upper=p_value_threshold)  # clip p-values to avoid color overflow\n",
    "\n",
    "        # 2.2 Create figure (2 subplots: top = count heatmap, bottom = p-value heatmap)\n",
    "        # Height adapts to number of valid Markers (rc_df_ordered.shape[0])\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 1 * rc_df_ordered.shape[0]))\n",
    "        fig.suptitle(f\"All Markers - X-axis Bins Analysis (Sample: {sample_type})\", fontsize=14, y=0.98)\n",
    "\n",
    "        # 2.3 Plot „Äåcount proportion heatmap„Äç (top subplot, based on reordered data)\n",
    "        im1 = ax1.imshow(rc_normalized.values, cmap='Blues', aspect='auto', vmin=min_count, vmax=max_count)\n",
    "        # Set axis labels (yticks use reordered Marker list)\n",
    "        ax1.set_xticks(tick_positions)\n",
    "        ax1.set_xticklabels(tick_labels, fontsize=15)\n",
    "        ax1.set_xlabel(\"offset from border\", fontsize=15)\n",
    "\n",
    "        # -------------------------- Key modification 2: y-axis labels in reordered order --------------------------\n",
    "        ax1.set_yticks(range(len(rc_df_ordered)))  # y-tick positions (match reordered rows)\n",
    "        ax1.set_yticklabels([word.capitalize() for word in rc_df_ordered.index], fontsize=15)  # y labels = target-order Markers\n",
    "        ax1.set_title(\"Positive Cell Proportion\", fontsize=15, pad=8)\n",
    "\n",
    "        # Add colorbar for count heatmap\n",
    "        cbar1 = plt.colorbar(im1, ax=ax1, shrink=0.8, aspect=20)\n",
    "        cbar1.outline.set_visible(False)\n",
    "        cbar1.set_label(\"Cell Proportion\", fontsize=15, labelpad=8)\n",
    "        cbar1.set_ticks([min_count, (min_count + max_count) / 2, max_count])\n",
    "        cbar1.set_ticklabels([f\"{x:.2f}\" for x in [min_count, (min_count + max_count) / 2, max_count]], fontsize=12)\n",
    "\n",
    "        # 2.4 Plot „Äåcorrected p-value heatmap„Äç (bottom subplot, based on reordered data)\n",
    "        im2 = ax2.imshow(cp_clipped.values, cmap='Reds_r', aspect='auto', vmin=0, vmax=p_value_threshold)\n",
    "        # Set axis labels (y-axis consistent with top subplot)\n",
    "        ax2.set_xticks(tick_positions)\n",
    "        ax2.set_xticklabels(tick_labels, fontsize=15)\n",
    "        ax2.set_xlabel(\"offset from border\", fontsize=15)\n",
    "\n",
    "        # -------------------------- Key modification 3: p-value heatmap y-axis order consistent with count heatmap --------------------------\n",
    "        ax2.set_yticks(range(len(cp_df_ordered)))  # y-tick positions (match reordered rows)\n",
    "        ax2.set_yticklabels([word.capitalize() for word in cp_df_ordered.index], fontsize=15)  # y labels = target-order Markers\n",
    "        ax2.set_title(f\"q-value (FDR, cutoff at {p_value_threshold})\", fontsize=15, pad=8)\n",
    "\n",
    "        # Add colorbar for p-value heatmap\n",
    "        cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8, aspect=20)\n",
    "        cbar2.outline.set_visible(False)\n",
    "        cbar2.set_label(\"FDR\", fontsize=10, labelpad=8)\n",
    "        cbar2.set_ticks([0, p_value_threshold / 2, p_value_threshold])\n",
    "        cbar2.set_ticklabels([f\"{x:.2f}\" for x in [0, p_value_threshold / 2, p_value_threshold]], fontsize=10)\n",
    "\n",
    "        # 2.5 Adjust layout (avoid label overlap)\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # reserve top space for title\n",
    "\n",
    "        # 2.6 Save integrated heatmap\n",
    "        heatmap_path = os.path.join(visualization_folder, \"all_markers_xbin_combined_heatmap\")\n",
    "        plt.savefig(heatmap_path + \".png\", dpi=1200, bbox_inches='tight')\n",
    "        plt.savefig(heatmap_path + \".pdf\", dpi=1200, bbox_inches='tight')\n",
    "        plt.savefig(heatmap_path + \".eps\", format='eps', dpi=1200, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"‚úÖ Saved integrated heatmap for all markers: {heatmap_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No valid results generated, skipping data saving and plotting\")\n",
    "\n",
    "print(\"\\n===== Analysis complete =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### two sample mode, Tmie-/- - WT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "from modules.judge_sig import (\n",
    "    create_position_bins,\n",
    "    two_step_stratified_sample,\n",
    "    count_positive_in_bins,\n",
    "    correct_grid_pvalues,\n",
    "    count_positive_in_x_bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_simulations = 10000\n",
    "num_xbins = 20\n",
    "num_ybins = 10\n",
    "correction_method = 'fdr'\n",
    "bx_min = -0.6\n",
    "bx_max = 0.6\n",
    "by_min = -0.6\n",
    "by_max = 0.6\n",
    "\n",
    "cell_num = 0\n",
    "random_num = 42\n",
    "\n",
    "# sample types\n",
    "sample_types = ['tmie', 'wt']\n",
    "\n",
    "# ----------------------\n",
    "# paths\n",
    "# ----------------------\n",
    "base_folder = 'path/to/your/data/'\n",
    "summary_folder = os.path.join(base_folder, \"summary\")\n",
    "sample_info_path = os.path.join(summary_folder, \"sample_info.csv\")\n",
    "results_file_path = os.path.join(summary_folder, 'vg_averageing_labels.csv')\n",
    "vg_size_path = os.path.join(summary_folder, 'vg_size.csv')\n",
    "\n",
    "print(f'Root directory: {base_folder}')\n",
    "print(f'Summary folder: {summary_folder}')\n",
    "print(f'Number of simulations: {n_simulations}')\n",
    "print(f'Number of x-bins: {num_xbins}, Number of y-bins: {num_ybins}')\n",
    "print(f'Correction method: {correction_method}')\n",
    "print(f'Sample types to compare: {sample_types}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Data loading & pre-processing\n",
    "# ----------------------\n",
    "def load_data(sample_type):\n",
    "    \"\"\"Load all necessary data for a given sample type.\"\"\"\n",
    "    try:\n",
    "        # load sample data\n",
    "        sample_data_path = os.path.join(summary_folder, sample_type + \"_summary_all.csv\")\n",
    "        sample_data = pd.read_csv(sample_data_path)\n",
    "        print(f\"Successfully loaded {sample_type} data: {len(sample_data)} rows\")\n",
    "        \n",
    "        # load BX/BY data\n",
    "        results_data = pd.read_csv(results_file_path, header=None)\n",
    "        BX = results_data.iloc[:, 0].values\n",
    "        BY = results_data.iloc[:, 1].values\n",
    "        print(f\"Successfully loaded BX/BY data: lengths {len(BX)}, {len(BY)}\")\n",
    "        \n",
    "        return sample_data, BX, BY\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {sample_type} data: {e}\")\n",
    "        raise\n",
    "\n",
    "def preprocess_data(data, vg_size):\n",
    "    \"\"\"Pre-process data: de-duplicate, compute standardised coordinates, etc.\"\"\"\n",
    "    # de-duplicate\n",
    "    original_count = len(data)\n",
    "    data = data.drop_duplicates(keep='first')\n",
    "    deduplicated_count = len(data)\n",
    "    removed_count = original_count - deduplicated_count\n",
    "    print(f\"After de-duplication: {deduplicated_count} records ({removed_count} duplicates removed)\")\n",
    "    \n",
    "    # compute standardised coordinates\n",
    "    avg_vg_size = vg_size.mean(axis=0).values\n",
    "    print(f\"Average VG size: {avg_vg_size}\")\n",
    "    \n",
    "    # locate coordinate columns\n",
    "    x_col = next((col for col in data.columns if col.endswith('warpedROIvar1')), None)\n",
    "    y_col = next((col for col in data.columns if col.endswith('warpedROIvar2')), None)\n",
    "    \n",
    "    if not x_col or not y_col:\n",
    "        missing = []\n",
    "        if not x_col: missing.append(\"column ending with warpedROIvar1\")\n",
    "        if not y_col: missing.append(\"column ending with warpedROIvar2\")\n",
    "        raise ValueError(f\"Required coordinate columns missing: {', '.join(missing)}\")\n",
    "    \n",
    "    print(f\"Coordinate columns found: X={x_col}, Y={y_col}\")\n",
    "    \n",
    "    # calculate standardised coordinates\n",
    "    data['standardized_x'] = data[x_col] / avg_vg_size[0]\n",
    "    data['standardized_y'] = data[y_col] / avg_vg_size[1]\n",
    "    \n",
    "    # extract positive-marker columns\n",
    "    is_positive_cols = [col for col in data.columns if col.endswith('_isPositive')]\n",
    "    if not is_positive_cols:\n",
    "        raise ValueError(\"No columns ending with '_isPositive' found; please check column names\")\n",
    "    print(f\"{len(is_positive_cols)} positive-marker columns found\")\n",
    "    \n",
    "    # sub-sample if required\n",
    "    if cell_num > 0:\n",
    "        data = two_step_stratified_sample(data, cell_num, random_num)\n",
    "    \n",
    "    return data, is_positive_cols, x_col, y_col\n",
    "\n",
    "# load VG size data\n",
    "vg_size = pd.read_csv(vg_size_path, header=None)\n",
    "\n",
    "# load & pre-process both sample types\n",
    "data1, BX, BY = load_data(sample_types[0])\n",
    "data2, BX, BY = load_data(sample_types[1])\n",
    "data1, positive_cols1, x_col, y_col = preprocess_data(data1, vg_size)\n",
    "data2, positive_cols2, x_col, y_col = preprocess_data(data2, vg_size)\n",
    "\n",
    "# ensure both samples share the same positive-marker columns\n",
    "common_markers = set(positive_cols1)\n",
    "common_markers.intersection_update(positive_cols2)\n",
    "\n",
    "common_markers = sorted(list(common_markers))\n",
    "print(f\"\\nMarkers common to both samples: {common_markers}\")\n",
    "\n",
    "# compute BX/BY boundaries (using combined range of both samples)\n",
    "all_BX = BX\n",
    "all_BY = BY\n",
    "\n",
    "order_list = [0, 7, 2, 6, 4, 5, 3, 1, 0]\n",
    "BX_ordered = BX[order_list]\n",
    "BY_ordered = BY[order_list]\n",
    "cs = CubicSpline(np.arange(len(BX_ordered)), np.c_[BX_ordered, BY_ordered], \n",
    "                axis=0, bc_type='periodic')\n",
    "t_fine = np.linspace(0, len(BX_ordered) - 1, 300)\n",
    "x_fine, y_fine = cs(t_fine).T\n",
    "\n",
    "actual_bx_min, actual_bx_max = x_fine.min(), x_fine.max()\n",
    "actual_by_min, actual_by_max = y_fine.min(), y_fine.max()\n",
    "\n",
    "# create bins\n",
    "bx_bins, by_bins = create_position_bins(\n",
    "    actual_bx_min, actual_bx_max,\n",
    "    actual_by_min, actual_by_max,\n",
    "    num_xbins, num_ybins\n",
    ")\n",
    "\n",
    "print(f\"BX range: {actual_bx_min:.2f} to {actual_bx_max:.2f}\")\n",
    "print(f\"BY range: {actual_by_min:.2f} to {actual_by_max:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Modified plotting function: only the difference in count proportion\n",
    "# ----------------------\n",
    "def plot_count_diff_heatmap(\n",
    "    result,\n",
    "    gene,\n",
    "    bx_min, bx_max, by_min, by_max,\n",
    "    BX, BY,\n",
    "    output_folder,\n",
    "    zero_color=[0.5, 0.5, 0.5],\n",
    "    order_list=[0, 7, 2, 6, 4, 5, 3, 1, 0]\n",
    "):\n",
    "    \"\"\"Plot inter-sample count difference: higher in tmie ‚Üí red, lower ‚Üí blue.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Decide which sample is tmie\n",
    "    if 'tmie' in sample_types[0]:\n",
    "        tmie_idx = 0\n",
    "        other_idx = 1\n",
    "    elif 'tmie' in sample_types[1]:\n",
    "        tmie_idx = 1\n",
    "        other_idx = 0\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è tmie sample not identified; using default order\")\n",
    "        tmie_idx = 1\n",
    "        other_idx = 0\n",
    "\n",
    "    # Difference: tmie ‚àí other (positive = red, negative = blue)\n",
    "    tmie_counts  = result['real_counts1'] if tmie_idx == 0 else result['real_counts2']\n",
    "    other_counts = result['real_counts1'] if other_idx == 0 else result['real_counts2']\n",
    "    count_diff   = tmie_counts - other_counts\n",
    "\n",
    "    rows, cols = count_diff.shape if count_diff is not None else (0, 0)\n",
    "\n",
    "    # Data check\n",
    "    if rows == 0 or cols == 0:\n",
    "        print(f\"‚ö†Ô∏è No count-difference data for {gene}, skipping plot\")\n",
    "        return\n",
    "\n",
    "    # ---------------------- Canvas setup ----------------------\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax  = plt.gca()\n",
    "\n",
    "    # Hide top & right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # ---------------------- Landmarks & smooth contour ----------------------\n",
    "    safe_order   = [i for i in order_list if i < len(BX)] if len(BX) > 0 else []\n",
    "    BX_ordered   = BX[safe_order] if len(safe_order) > 0 else BX\n",
    "    BY_ordered   = BY[safe_order] if len(safe_order) > 0 else BY\n",
    "\n",
    "    if len(BX_ordered) >= 3:\n",
    "        from scipy.interpolate import CubicSpline\n",
    "        cs = CubicSpline(np.arange(len(BX_ordered)),\n",
    "                         np.c_[BX_ordered, BY_ordered],\n",
    "                         axis=0, bc_type='periodic')\n",
    "        t_fine = np.linspace(0, len(BX_ordered) - 1, 300)\n",
    "        x_fine, y_fine = cs(t_fine).T\n",
    "        ax.plot(x_fine, y_fine, color=1 - np.array(zero_color), lw=2)\n",
    "    ax.plot(BX, BY, '+', ms=10, lw=2, color=np.array(zero_color) * 0.6)\n",
    "\n",
    "    # ---------------------- Main heatmap: count difference ----------------------\n",
    "    max_abs = np.max(np.abs(count_diff))\n",
    "    vmin, vmax = -max_abs, max_abs\n",
    "\n",
    "    im = ax.pcolormesh(\n",
    "        np.linspace(bx_min, bx_max, cols),\n",
    "        np.linspace(by_min, by_max, rows),\n",
    "        count_diff,\n",
    "        cmap='coolwarm',  # blue ‚Üí white ‚Üí red\n",
    "        vmin=vmin,\n",
    "        vmax=vmax\n",
    "    )\n",
    "    ax.set_xlim(bx_min, bx_max)\n",
    "    ax.set_ylim(by_min, by_max)\n",
    "    ax.set_title(f'{gene} - count difference (tmie ‚àí {sample_types[other_idx]})', fontsize=12, pad=10)\n",
    "\n",
    "    # ---------------------- Colorbar ----------------------\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.15])\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_label('count difference', rotation=270, labelpad=15)\n",
    "    cbar.outline.set_visible(False)\n",
    "\n",
    "    cbar_ax.text(0.5, 1.10, 'higher in tmie ‚Üí',\n",
    "                 ha='center', va='bottom', fontsize=10, transform=cbar_ax.transAxes)\n",
    "    cbar_ax.text(0.5, -0.20, '‚Üê lower in tmie',\n",
    "                 ha='center', va='top', fontsize=10, transform=cbar_ax.transAxes)\n",
    "\n",
    "    # ---------------------- Save difference heatmap ----------------------\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, bottom=0.15, top=0.85)\n",
    "    output_path = os.path.join(output_folder, f'{gene}_count_diff.png')\n",
    "    fig.savefig(output_path, dpi=1200, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"‚úÖ Count-difference heatmap saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 2. Single-panel function 2: heatmap of inter-sample p-value differences\n",
    "# ----------------------\n",
    "def plot_sample_diff_p_heatmap(\n",
    "    result,\n",
    "    gene,\n",
    "    bx_min, bx_max, by_min, by_max,\n",
    "    BX, BY,\n",
    "    output_folder,\n",
    "    zero_color=[0.5, 0.5, 0.5],\n",
    "    p_threshold=0.05,\n",
    "    order_list=[0, 7, 2, 6, 4, 5, 3, 1, 0]\n",
    "):\n",
    "    \"\"\"Plot the corrected p-value heatmap of inter-sample differences (no extra subplots).\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    corrected_p = result['corrected_p']\n",
    "    rows, cols = corrected_p.shape if corrected_p is not None else (0, 0)\n",
    "\n",
    "    # Skip if p-value matrix is empty\n",
    "    if rows == 0 or cols == 0:\n",
    "        print(f\"‚ö†Ô∏è No p-value data for {gene}, skipping p-value heatmap\")\n",
    "        return\n",
    "\n",
    "    # -------------------------- Single-panel layout (p-value heatmap only) --------------------------\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = plt.gca()  # one single main axis\n",
    "\n",
    "    # Hide top & right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # -------------------------- Landmarks & smooth contour (safe handling) --------------------------\n",
    "    safe_order = [i for i in order_list if i < len(BX)] if len(BX) > 0 else []\n",
    "    BX_ordered = BX[safe_order] if len(safe_order) > 0 else BX\n",
    "    BY_ordered = BY[safe_order] if len(safe_order) > 0 else BY\n",
    "\n",
    "    if len(BX_ordered) >= 3:\n",
    "        cs = CubicSpline(np.arange(len(BX_ordered)), np.c_[BX_ordered, BY_ordered],\n",
    "                        axis=0, bc_type='periodic')\n",
    "        t_fine = np.linspace(0, len(BX_ordered) - 1, 300)\n",
    "        x_fine, y_fine = cs(t_fine).T\n",
    "        ax.plot(x_fine, y_fine, color=1 - np.array(zero_color), linewidth=2)\n",
    "    ax.plot(BX, BY, '+', markersize=10, linewidth=2, color=np.array(zero_color) * 0.6)\n",
    "\n",
    "    # -------------------------- Main panel: corrected p-value heatmap --------------------------\n",
    "    # Clip p-values above threshold to avoid colour overflow\n",
    "    p_clipped = np.clip(corrected_p, 0, p_threshold)\n",
    "    im = ax.pcolormesh(\n",
    "        np.linspace(bx_min, bx_max, cols),\n",
    "        np.linspace(by_min, by_max, rows),\n",
    "        p_clipped,\n",
    "        cmap='Reds_r',  # darker red = smaller p-value\n",
    "        vmin=0,\n",
    "        vmax=p_threshold\n",
    "    )\n",
    "    ax.set_xlim(bx_min, bx_max)\n",
    "    ax.set_ylim(by_min, by_max)\n",
    "    ax.set_title(f'{gene} - {sample_types[0]} vs {sample_types[1]} FDR Heatmap', fontsize=12, pad=10)\n",
    "\n",
    "    # -------------------------- Colour bar (separate axes) --------------------------\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.15])\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax)\n",
    "    cbar.set_ticks([0, p_threshold / 2, p_threshold])\n",
    "    cbar.set_ticklabels([f'{x:.3f}' for x in [0, p_threshold / 2, p_threshold]])\n",
    "    cbar.outline.set_visible(False)\n",
    "    cbar_ax.text(\n",
    "        x=0.5, y=1.10, s='FDR',\n",
    "        ha='center', va='bottom', fontsize=10, transform=cbar_ax.transAxes\n",
    "    )\n",
    "\n",
    "    # -------------------------- Save single p-value figure --------------------------\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, bottom=0.15, top=0.85)\n",
    "    output_path = os.path.join(output_folder, f'{gene}_diff_p.png')\n",
    "    fig.savefig(output_path, dpi=1200, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"‚úÖ Saved {gene} difference p-value heatmap: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Revised Monte-Carlo simulation function\n",
    "# ----------------------\n",
    "def monte_carlo_simulation(data1, data2, is_positive_col=None,\n",
    "                          x_col='standardized_x', y_col='standardized_y',\n",
    "                          bx_bins=None, by_bins=None, n_simulations=10000):\n",
    "    \"\"\"\n",
    "    Monte-Carlo simulation supporting two modes:\n",
    "    1. When data2 is provided: compare the spatial distribution of is_positive_col\n",
    "       between data1 and data2.\n",
    "    2. When data2 is None: compare the observed distribution in data1 against\n",
    "       a null distribution obtained by random shuffling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data1 : pd.DataFrame\n",
    "        Primary dataset.\n",
    "    data2 : pd.DataFrame | None\n",
    "        Second dataset for comparison (mode 1); if None, mode 2 is used.\n",
    "    is_positive_col : str\n",
    "        Name of the positive-marker column.\n",
    "    x_col, y_col : str\n",
    "        Coordinate columns.\n",
    "    bx_bins, by_bins : array-like\n",
    "        Bin edges for x and y axes.\n",
    "    n_simulations : int\n",
    "        Number of Monte-Carlo iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing real counts, simulated counts, and p-values.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- Mode 1: two-sample comparison ----------\n",
    "    if data2 is not None and is_positive_col is not None:\n",
    "        # Filter valid entries\n",
    "        filtered1 = data1[data1[is_positive_col] != -1].copy()\n",
    "        filtered1[is_positive_col] = filtered1[is_positive_col].astype(bool)\n",
    "        sum1 = np.sum(filtered1[is_positive_col])\n",
    "\n",
    "        filtered2 = data2[data2[is_positive_col] != -1].copy()\n",
    "        filtered2[is_positive_col] = filtered2[is_positive_col].astype(bool)\n",
    "        sum2 = np.sum(filtered2[is_positive_col])\n",
    "\n",
    "        # Real observed counts\n",
    "        counts1 = count_positive_in_bins(filtered1, is_positive_col, x_col, y_col, bx_bins, by_bins)\n",
    "        counts2 = count_positive_in_bins(filtered2, is_positive_col, x_col, y_col, bx_bins, by_bins)\n",
    "\n",
    "        # Real difference (proportions)\n",
    "        real_diff = counts1 / sum1 - counts2 / sum2\n",
    "        total_real = np.sum(np.abs(real_diff))\n",
    "        if total_real == 0:\n",
    "            print(f\"‚ö†Ô∏è Real difference for {is_positive_col} is zero between samples, skipping simulation\")\n",
    "            return None\n",
    "\n",
    "        # Storage for simulated differences\n",
    "        sim_diffs = np.zeros((n_simulations, *real_diff.shape))\n",
    "\n",
    "        # Monte-Carlo loop\n",
    "        for i in tqdm(range(n_simulations), desc=f\"MC sim {is_positive_col} sample comparison\"):\n",
    "            # Shuffle positive labels within each sample\n",
    "            shuffled1 = filtered1[is_positive_col].values.copy()\n",
    "            shuffled2 = filtered2[is_positive_col].values.copy()\n",
    "            np.random.shuffle(shuffled1)\n",
    "            np.random.shuffle(shuffled2)\n",
    "\n",
    "            temp1 = filtered1.copy()\n",
    "            temp1[is_positive_col] = shuffled1\n",
    "            temp2 = filtered2.copy()\n",
    "            temp2[is_positive_col] = shuffled2\n",
    "\n",
    "            sim_counts1 = count_positive_in_bins(temp1, is_positive_col, x_col, y_col, bx_bins, by_bins)\n",
    "            sim_counts2 = count_positive_in_bins(temp2, is_positive_col, x_col, y_col, bx_bins, by_bins)\n",
    "\n",
    "            sim_diffs[i] = sim_counts1 / sum1 - sim_counts2 / sum2\n",
    "\n",
    "        # P-value: proportion of |simulated| ‚â• |real|\n",
    "        p_values = (np.sum(np.abs(sim_diffs) >= np.abs(real_diff), axis=0) + 1) / (n_simulations + 1)\n",
    "\n",
    "        return {\n",
    "            'is_positive_col': is_positive_col,\n",
    "            'gene': is_positive_col.replace('_isPositive', ''),\n",
    "            'real_counts1': counts1 / sum1,\n",
    "            'real_counts2': counts2 / sum2,\n",
    "            'real_diff': real_diff,\n",
    "            'sim_diffs': sim_diffs,\n",
    "            'p_values': p_values,\n",
    "            'corrected_p': None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Execute analysis\n",
    "# ----------------------\n",
    "# ----------------------\n",
    "# Save results & plotting\n",
    "# ----------------------\n",
    "min_count = 0\n",
    "max_count = 0.02\n",
    "\n",
    "# Create output folder\n",
    "if cell_num > 0:\n",
    "    comparison_results_folder = os.path.join(\n",
    "        summary_folder, \n",
    "        f\"grid_comparison_{sample_types[0]}_vs_{sample_types[1]}_{cell_num}\"\n",
    "    )\n",
    "else:\n",
    "    comparison_results_folder = os.path.join(\n",
    "        summary_folder, \n",
    "        f\"grid_comparison_{sample_types[0]}_vs_{sample_types[1]}\"\n",
    "    )\n",
    "os.makedirs(comparison_results_folder, exist_ok=True)\n",
    "\n",
    "print(\"\\n===== Starting Monte-Carlo comparison =====\")\n",
    "comparison_results = []\n",
    "\n",
    "# Compare every common marker between the two samples\n",
    "for marker in common_markers:\n",
    "    gene = marker.replace('_isPositive', '')\n",
    "    x_col = 'standardized_x'\n",
    "    y_col = 'standardized_y'\n",
    "\n",
    "    # Ensure both samples have the marker and coordinates\n",
    "    valid = True\n",
    "    for st in sample_types:\n",
    "        if x_col not in data1.columns or y_col not in data2.columns:\n",
    "            print(f\"‚ö†Ô∏è Warning: {st} missing standardised coordinates, skipping {marker}\")\n",
    "            valid = False\n",
    "            break\n",
    "        if marker not in common_markers:\n",
    "            print(f\"‚ö†Ô∏è Warning: {st} missing marker {marker}, skipping\")\n",
    "            valid = False\n",
    "            break\n",
    "\n",
    "    if not valid:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n===== Comparing {marker} between {sample_types[0]} and {sample_types[1]} =====\")\n",
    "\n",
    "    # Run two-sample Monte-Carlo simulation\n",
    "    result = monte_carlo_simulation(\n",
    "        data1, data2, marker,\n",
    "        x_col, y_col, bx_bins, by_bins, n_simulations\n",
    "    )\n",
    "\n",
    "    if result is not None:\n",
    "        total_diff = np.sum(np.abs(result['real_diff']))\n",
    "        print(f\"Total real difference for {marker}: {total_diff}\")\n",
    "\n",
    "        if total_diff > 0:\n",
    "            # Correct p-values\n",
    "            result['corrected_p'] = correct_grid_pvalues(result['p_values'], method=correction_method)\n",
    "            comparison_results.append(result)\n",
    "            print(f\"‚úÖ Comparison for {marker} completed\")\n",
    "        else:\n",
    "            print(f\"‚ùå Total real difference for {marker} is zero, not added to results\")\n",
    "    else:\n",
    "        print(f\"‚ùå Comparison for {marker} failed, no result generated\")\n",
    "\n",
    "# ----------------------\n",
    "# Revised plotting logic: only difference and p-value heatmaps\n",
    "# ----------------------\n",
    "if comparison_results:\n",
    "    print(\"\\n===== Saving inter-sample comparison results and plotting difference heatmaps =====\")\n",
    "    for result in comparison_results:\n",
    "        gene = result['gene']\n",
    "\n",
    "        # 1. Save raw data\n",
    "        np.savetxt(\n",
    "            os.path.join(comparison_results_folder, f'{gene}_{sample_types[0]}_counts.csv'),\n",
    "            result['real_counts1'], delimiter=',', fmt='%d'\n",
    "        )\n",
    "        np.savetxt(\n",
    "            os.path.join(comparison_results_folder, f'{gene}_{sample_types[1]}_counts.csv'),\n",
    "            result['real_counts2'], delimiter=',', fmt='%d'\n",
    "        )\n",
    "        np.savetxt(\n",
    "            os.path.join(comparison_results_folder, f'{gene}_diff_counts.csv'),\n",
    "            result['real_diff'], delimiter=',', fmt='%d'\n",
    "        )\n",
    "        np.savetxt(\n",
    "            os.path.join(comparison_results_folder, f'{gene}_corrected_p.csv'),\n",
    "            result['corrected_p'], delimiter=',', fmt='%.6f'\n",
    "        )\n",
    "\n",
    "        # 2. Data validation\n",
    "        required_cols = [f'{gene}_isPositive', 'standardized_x', 'standardized_y']\n",
    "        s1_valid = all(col in data1.columns for col in required_cols)\n",
    "        s2_valid = all(col in data2.columns for col in required_cols)\n",
    "\n",
    "        if not s1_valid or not s2_valid:\n",
    "            missing = []\n",
    "            if not s1_valid:\n",
    "                missing.append(\n",
    "                    f\"{sample_types[0]}: \"\n",
    "                    f\"{', '.join([c for c in required_cols if c not in data1.columns])}\"\n",
    "                )\n",
    "            if not s2_valid:\n",
    "                missing.append(\n",
    "                    f\"{sample_types[1]}: \"\n",
    "                    f\"{', '.join([c for c in required_cols if c not in data2.columns])}\"\n",
    "                )\n",
    "            print(f\"‚ö†Ô∏è {gene} missing columns: {'; '.join(missing)}, skipping plots\")\n",
    "            continue\n",
    "\n",
    "        # 3. Plot only difference and p-value heatmaps\n",
    "        # Difference heatmap (red = higher in tmie, blue = lower)\n",
    "        plot_count_diff_heatmap(\n",
    "            result=result,\n",
    "            gene=gene,\n",
    "            bx_min=bx_min,\n",
    "            bx_max=bx_max,\n",
    "            by_min=by_min,\n",
    "            by_max=by_max,\n",
    "            BX=BX,\n",
    "            BY=BY,\n",
    "            output_folder=comparison_results_folder\n",
    "        )\n",
    "\n",
    "        # p-value heatmap of inter-sample difference\n",
    "        plot_sample_diff_p_heatmap(\n",
    "            result=result,\n",
    "            gene=gene,\n",
    "            bx_min=bx_min,\n",
    "            bx_max=bx_max,\n",
    "            by_min=by_min,\n",
    "            by_max=by_max,\n",
    "            BX=BX,\n",
    "            BY=BY,\n",
    "            output_folder=comparison_results_folder\n",
    "        )\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No valid comparison results generated\")\n",
    "\n",
    "print(\"\\n===== All plotting finished =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xcol_two_sample_monte(data1, data2, is_positive_col, x_col, bx_bins, n_simulations):\n",
    "    \"\"\"\n",
    "    Assess significance of between-sample differences along the X-axis.\n",
    "    \n",
    "    Logic: obtain per-sample column counts first, then compare differences\n",
    "    via Monte-Carlo simulation.\n",
    "    \"\"\"\n",
    "    # Remove invalid data and convert to Boolean\n",
    "    filtered1 = data1[data1[is_positive_col] != -1].copy()\n",
    "    filtered1[is_positive_col] = filtered1[is_positive_col].astype(bool)\n",
    "    filtered2 = data2[data2[is_positive_col] != -1].copy()\n",
    "    filtered2[is_positive_col] = filtered2[is_positive_col].astype(bool)\n",
    "\n",
    "    # STEP 1: compute real X-bin counts for each sample\n",
    "    result1 = count_positive_in_x_bins(filtered1, is_positive_col, x_col, bx_bins)\n",
    "    result2 = count_positive_in_x_bins(filtered2, is_positive_col, x_col, bx_bins)\n",
    "    sum1 = np.sum(result1)\n",
    "    sum2 = np.sum(result2)\n",
    "\n",
    "    if result1 is None or result2 is None:\n",
    "        print(f\"‚ö†Ô∏è {is_positive_col}: single-sample x-bin counting failed, two-sample comparison skipped\")\n",
    "        return None\n",
    "\n",
    "    # Normalised column counts\n",
    "    real_counts1 = result1 / sum1   # sample-1 proportions  (shape: num_xbins,)\n",
    "    real_counts2 = result2 / sum2   # sample-2 proportions  (shape: num_xbins,)\n",
    "\n",
    "    # Observed difference  (sample1 - sample2, can be changed to tmie - wt if desired)\n",
    "    real_diff = real_counts1 - real_counts2\n",
    "    total_real_diff = np.sum(np.abs(real_diff))\n",
    "    if total_real_diff == 0:\n",
    "        print(f\"‚ö†Ô∏è {is_positive_col}: total real difference between samples is zero, simulation skipped\")\n",
    "        return None\n",
    "\n",
    "    # STEP 2: Monte-Carlo simulation  (shuffle labels and re-compute differences)\n",
    "    orig1 = filtered1[is_positive_col].values.copy()   # keep original labels\n",
    "    sim_diffs = np.zeros((n_simulations, len(real_diff)))\n",
    "\n",
    "    for i in tqdm(range(n_simulations), desc=f\"Simulating column diff {is_positive_col}\"):\n",
    "        # shuffle sample-1 labels  (sample-2 can be treated likewise if needed)\n",
    "        shuffled1 = orig1.copy()\n",
    "        np.random.shuffle(shuffled1)\n",
    "\n",
    "        temp1 = filtered1.copy()\n",
    "        temp1[is_positive_col] = shuffled1\n",
    "        temp2 = filtered2.copy()   # shuffle similarly if required\n",
    "\n",
    "        # simulated counts\n",
    "        sim_result1 = count_positive_in_x_bins(temp1, is_positive_col, x_col, bx_bins)\n",
    "        sim_result2 = count_positive_in_x_bins(temp2, is_positive_col, x_col, bx_bins)\n",
    "        if sim_result1 is not None and sim_result2 is not None:\n",
    "            sim_diff = sim_result1 / sum1 - sim_result2 / sum2\n",
    "            sim_diffs[i] = sim_diff\n",
    "\n",
    "    # STEP 3: compute p-values  (proportion of |simulated| ‚â• |real|)\n",
    "    p_matrix = np.abs(sim_diffs) >= np.abs(real_diff)\n",
    "    p_values = (np.sum(p_matrix, axis=0) + 1) / (n_simulations + 1)\n",
    "\n",
    "    # Return column-difference results\n",
    "    return {\n",
    "        'is_positive_col': is_positive_col,\n",
    "        'gene': is_positive_col.replace('_isPositive', ''),\n",
    "        'real_counts1': real_counts1,   # sample-1 X-bin proportions\n",
    "        'real_counts2': real_counts2,   # sample-2 X-bin proportions\n",
    "        'real_diff': real_diff,         # column difference  (sample1 - sample2)\n",
    "        'sim_diffs': sim_diffs,         # array of simulated differences\n",
    "        'p_values': p_values,           # uncorrected p-values\n",
    "        'corrected_p': None             # slot for corrected p-values\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# 5. Batch-run column-wise difference analysis for all markers (code unchanged)\n",
    "# ----------------------\n",
    "print(\"\\n===== Starting two-sample column-difference significance analysis along X-axis =====\")\n",
    "xcol_diff_results = []  # store results for all markers\n",
    "\n",
    "for col in common_markers:\n",
    "    gene = col.replace('_isPositive', '')\n",
    "    x_col = 'standardized_x'  # same as in the main pipeline\n",
    "\n",
    "    # check coordinate column existence\n",
    "    if x_col not in data1.columns or x_col not in data2.columns:\n",
    "        print(f\"‚ö†Ô∏è Warning: {sample_types[0]} (wt) or {sample_types[1]} (tmie) missing X-axis coordinate column {x_col}, skipping {col}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n===== Analysing marker: {col} (gene: {gene}) =====\")\n",
    "    print(f\"X-axis coordinate column: {x_col}\")\n",
    "    print(f\"Number of X-bins: {num_xbins}\")\n",
    "\n",
    "    # perform two-sample column-difference analysis (function assumed pre-defined)\n",
    "    result = xcol_two_sample_monte(\n",
    "        data1=data1,\n",
    "        data2=data2,\n",
    "        is_positive_col=col,\n",
    "        x_col=x_col,\n",
    "        bx_bins=bx_bins,\n",
    "        n_simulations=n_simulations\n",
    "    )\n",
    "\n",
    "    if result is not None:\n",
    "        total_real = np.sum(np.abs(result['real_diff']))\n",
    "        print(f\"Column-difference sum for {col}: {total_real}\")\n",
    "\n",
    "        if total_real > 0:\n",
    "            # correct p-values (correct_grid_pvalues assumed pre-defined)\n",
    "            result['corrected_p'] = correct_grid_pvalues(result['p_values'], method=correction_method)\n",
    "\n",
    "            # store proportions for later plotting\n",
    "            sum1 = np.sum(result['real_counts1'])\n",
    "            sum2 = np.sum(result['real_counts2'])\n",
    "            result['tmie_proportion'] = result['real_counts1']\n",
    "            result['wt_proportion'] = result['real_counts2']\n",
    "            result['proportion_diff'] = result['tmie_proportion'] - result['wt_proportion']\n",
    "\n",
    "            xcol_diff_results.append(result)\n",
    "            print(f\"‚úÖ Column-difference analysis for {col} completed (proportions & differences calculated)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Column-difference sum for {col} is zero, not added to results\")\n",
    "    else:\n",
    "        print(f\"‚ùå Column-difference analysis for {col} failed, no result generated\")\n",
    "\n",
    "print(f\"\\n===== X-axis column-difference analysis finished: {len(xcol_diff_results)} marker(s) succeeded =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if xcol_diff_results:\n",
    "    print(\"\\n===== Saving X-axis column-difference results (including proportions & differences) =====\")\n",
    "    # Define paths (separate result files and visualizations)\n",
    "    results_folder = comparison_results_folder\n",
    "    visualization_folder = os.path.join(comparison_results_folder, \"grid_visualizations\")\n",
    "    os.makedirs(visualization_folder, exist_ok=True)\n",
    "\n",
    "    for result in xcol_diff_results:\n",
    "        gene = result['gene']\n",
    "\n",
    "        # ---------------------- Original file saves (kept) ----------------------\n",
    "        # 1. Real counts (wt=data1, tmie=data2)\n",
    "        np.savetxt(\n",
    "            os.path.join(results_folder, f'{gene}_wt_xcol_counts.csv'),\n",
    "            result['real_counts1'],\n",
    "            delimiter=',',\n",
    "            fmt='%.6f'\n",
    "        )\n",
    "        np.savetxt(\n",
    "            os.path.join(results_folder, f'{gene}_tmie_xcol_counts.csv'),\n",
    "            result['real_counts2'],\n",
    "            delimiter=',',\n",
    "            fmt='%.6f'\n",
    "        )\n",
    "\n",
    "        # 2. Count proportions (wt and tmie)\n",
    "        np.savetxt(\n",
    "            os.path.join(results_folder, f'{gene}_wt_xcol_proportions.csv'),\n",
    "            result['wt_proportion'],\n",
    "            delimiter=',',\n",
    "            fmt='%.6f'\n",
    "        )\n",
    "        np.savetxt(\n",
    "            os.path.join(results_folder, f'{gene}_tmie_xcol_proportions.csv'),\n",
    "            result['tmie_proportion'],\n",
    "            delimiter=',',\n",
    "            fmt='%.6f'\n",
    "        )\n",
    "\n",
    "        # ---------------------- NEW: save proportion-difference file (tmie ‚àí wt) ----------------------\n",
    "        np.savetxt(\n",
    "            os.path.join(results_folder, f'{gene}_tmie_minus_wt_proportion_diff.csv'),\n",
    "            result['proportion_diff'],\n",
    "            delimiter=',',\n",
    "            fmt='%.6f'\n",
    "        )\n",
    "\n",
    "        # 3. Original difference & p-value files\n",
    "        np.savetxt(\n",
    "            os.path.join(results_folder, f'{gene}_xcol_real_diff.csv'),\n",
    "            result['real_diff'],\n",
    "            delimiter=',',\n",
    "            fmt='%.6f'\n",
    "        )\n",
    "        np.savetxt(\n",
    "            os.path.join(results_folder, f'{gene}_xcol_corrected_p.csv'),\n",
    "            result['corrected_p'],\n",
    "            delimiter=',',\n",
    "            fmt='%.6f'\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Results for {gene} saved:\")\n",
    "        print(f\"   - Proportion-difference file: {gene}_tmie_minus_wt_proportion_diff.csv\")\n",
    "        print(f\"   - Other files: counts / proportions / p-values (original format)\")\n",
    "\n",
    "    # 1. Extract X-axis bin information\n",
    "    x_bin_edges = np.linspace(x_fine.min(), x_fine.max(), num_xbins + 1)  # use original x-bin boundaries\n",
    "    x_bin_labels = [f\"Bin{i+1}\\n[{x_bin_edges[i]:.2f}-{x_bin_edges[i+1]:.2f}]\"\n",
    "                    for i in range(len(x_bin_edges) - 1)]\n",
    "    x_bin_num = len(x_bin_labels)  # total number of x-bins\n",
    "\n",
    "    # 2. Merge difference and p-value data for all genes\n",
    "    marker_list = []               # valid gene list\n",
    "    proportion_diff_all = []       # proportion difference (tmie ‚àí wt): rows=genes, cols=bins\n",
    "    corrected_p_all = []           # corrected p-values\n",
    "\n",
    "    # ---------- 1. Compute 20 bin indices ----------\n",
    "    min_bin_idx = np.digitize(x_fine.min(), bx_bins) - 1\n",
    "    max_bin_idx = np.digitize(x_fine.max(), bx_bins) - 1\n",
    "    zero_bin_idx = np.digitize(0, bx_bins) - 1\n",
    "    x_bins_indices = np.arange(min_bin_idx, min_bin_idx + 20)  # fixed 20 bins\n",
    "    x_offsets = x_bins_indices - zero_bin_idx  # offset relative to 0\n",
    "\n",
    "    # ---------- 2. Pick ticks every 5 steps, centred at 0, only within existing 20 offsets ----------\n",
    "    step = 5\n",
    "    low = int(np.floor(x_offsets.min() / step) * step)\n",
    "    high = int(np.ceil(x_offsets.max() / step) * step)\n",
    "    tick_labels = np.arange(low, high + 1, step)  # multiples of 5\n",
    "    tick_labels = tick_labels[np.isin(tick_labels, x_offsets)]  # ensure existence\n",
    "\n",
    "    # ---------- 3. Corresponding plot positions ----------\n",
    "    tick_positions = [np.where(x_offsets == lab)[0][0] for lab in tick_labels]\n",
    "\n",
    "    for result in xcol_diff_results:\n",
    "        gene = result['gene']\n",
    "        diff = result['proportion_diff']\n",
    "        corr_p = result['corrected_p']\n",
    "\n",
    "        diff = diff[min_bin_idx:max_bin_idx]\n",
    "        corr_p = corr_p[min_bin_idx:max_bin_idx]\n",
    "\n",
    "        marker_list.append(gene)\n",
    "        proportion_diff_all.append(diff)\n",
    "        corrected_p_all.append(corr_p)\n",
    "\n",
    "    diff_df = pd.DataFrame(proportion_diff_all,\n",
    "                          index=marker_list,\n",
    "                          columns=[f\"Bin{i+1}\" for i in range(x_bin_num)])\n",
    "    corr_p_df = pd.DataFrame(corrected_p_all,\n",
    "                            index=marker_list,\n",
    "                            columns=[f\"Bin{i+1}\" for i in range(x_bin_num)])\n",
    "\n",
    "    diff_df.to_csv(os.path.join(results_folder, 'all_tmie_minus_wt_proportion_diff.csv'), index=True)\n",
    "    corr_p_df.to_csv(os.path.join(results_folder, 'all_tmie_minus_wt_p_adj.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = pd.read_csv(os.path.join(results_folder, 'all_tmie_minus_wt_proportion_diff.csv'),\n",
    "                      index_col=0, header=0)\n",
    "corr_p_df = pd.read_csv(os.path.join(results_folder, 'all_tmie_minus_wt_p_adj.csv'),\n",
    "                        index_col=0, header=0)\n",
    "\n",
    "# ----------------------\n",
    "# 6. Save analysis results (including proportion-difference files)\n",
    "# ----------------------\n",
    "target_marker_order = ['a', 'b', 'c', 'd', 'e']  # top-to-bottom order\n",
    "\n",
    "if xcol_diff_results:\n",
    "    # ---------------------- Core update: plot \"proportion difference + corrected p\" twin heatmaps ----------------------\n",
    "    print(\"\\n===== Plotting integrated heatmap: proportion difference & corrected p-values =====\")\n",
    "    # Plotting parameters (adjustable)\n",
    "    diff_abs_max = 0.1   # maximum absolute proportion difference for symmetric colour scale (e.g. ¬±0.1)\n",
    "    p_threshold = 0.05   # significance threshold\n",
    "\n",
    "    # 1. Extract X-axis bin information\n",
    "    x_bin_edges = np.linspace(x_fine.min(), x_fine.max(), num_xbins + 1)  # original bin boundaries\n",
    "    x_bin_labels = [f\"Bin{i+1}\\n[{x_bin_edges[i]:.2f}-{x_bin_edges[i+1]:.2f}]\"\n",
    "                    for i in range(len(x_bin_edges) - 1)]\n",
    "    x_bin_num = len(x_bin_labels)  # total number of x-bins\n",
    "\n",
    "    # 3. Skip if no valid data\n",
    "    if len(marker_list) == 0:\n",
    "        print(\"‚ö†Ô∏è No valid gene data, heatmap plotting skipped\")\n",
    "    else:\n",
    "        # 4. Convert to DataFrame\n",
    "        # 1. Filter: keep only target Markers\n",
    "        diff_df_filtered = diff_df.loc[diff_df.index.isin(target_marker_order)]   # count data filter\n",
    "        corr_p_df_filtered = corr_p_df.loc[corr_p_df.index.isin(target_marker_order)]  # p-value filter\n",
    "\n",
    "        # 2. Reorder rows according to target_marker_order (core step)\n",
    "        diff_df = diff_df_filtered.reindex(target_marker_order)   # proportion difference in target order\n",
    "        corr_p_df = corr_p_df_filtered.reindex(target_marker_order)  # p-values in target order\n",
    "\n",
    "        # 5. Data preprocessing\n",
    "        diff_clipped = diff_df.clip(lower=-diff_abs_max, upper=diff_abs_max)  # clip to avoid colour overflow\n",
    "        corr_p_clipped = corr_p_df.clip(upper=p_threshold)                    # cap p-values at threshold\n",
    "\n",
    "        # 6. Create twin subplots (top: proportion difference; bottom: corrected p-values)\n",
    "        fig, (ax1, ax2) = plt.subplots(\n",
    "            2, 1,\n",
    "            figsize=(12, 1 * len(target_marker_order)),  # height adapts to gene number\n",
    "            gridspec_kw={'height_ratios': [1, 0.8]}      # difference map slightly taller\n",
    "        )\n",
    "        fig.suptitle(\"X-axis Bins Analysis: wt vs tmie\", fontsize=14, y=0.98)\n",
    "\n",
    "        # ---------------------- Subplot 1: proportion-difference heatmap (core update) ----------------------\n",
    "        # Colour map: RdBu_r (blue ‚Üí white ‚Üí red, reversed: red = tmie higher)\n",
    "        im1 = ax1.imshow(\n",
    "            diff_clipped.values,\n",
    "            cmap='RdBu_r',        # red = tmie higher, blue = tmie lower, white = no difference\n",
    "            aspect='auto',\n",
    "            vmin=-diff_abs_max,   # symmetric colour scale\n",
    "            vmax=diff_abs_max\n",
    "        )\n",
    "        # Axis settings\n",
    "        ax1.set_xticks(tick_positions)\n",
    "        ax1.set_xticklabels(tick_labels, fontsize=15)\n",
    "        ax1.set_xlabel(\"offset from border\", fontsize=10)\n",
    "\n",
    "        ax1.set_yticks(range(len(target_marker_order)))\n",
    "        ax1.set_yticklabels([word.capitalize() for word in diff_clipped.index], fontsize=15)\n",
    "        ax1.set_ylabel(\"Genes\", fontsize=12, labelpad=10)\n",
    "        ax1.set_title(\n",
    "            f\"Proportion Difference (tmie - wt)\\n(Blue: tmie < wt | Red: tmie > wt)\",\n",
    "            fontsize=15, pad=8\n",
    "        )\n",
    "\n",
    "        # Colour bar for difference map (with ¬± labels)\n",
    "        cbar1 = plt.colorbar(im1, ax=ax1, shrink=0.8, aspect=20)\n",
    "        cbar1.outline.set_visible(False)\n",
    "        cbar1.set_label(\"tmie - wt Proportion\", fontsize=15, labelpad=8)\n",
    "        cbar1.set_ticks([-diff_abs_max, 0, diff_abs_max])\n",
    "        cbar1.set_ticklabels([f\"-{diff_abs_max:.3f}\", \"0\", f\"+{diff_abs_max:.3f}\"])\n",
    "\n",
    "        # ---------------------- Subplot 2: corrected p-value heatmap (kept for significance) ----------------------\n",
    "        im2 = ax2.imshow(\n",
    "            corr_p_clipped.values,\n",
    "            cmap='Reds_r',       # red = small p (significant), white = large p (non-significant)\n",
    "            aspect='auto',\n",
    "            vmin=0,\n",
    "            vmax=p_threshold\n",
    "        )\n",
    "        # Axis settings (hide y-labels, same gene order as top panel)\n",
    "        ax2.set_xticks(tick_positions)\n",
    "        ax2.set_xticklabels(tick_labels, fontsize=15)\n",
    "        ax2.set_xlabel(\"offset from border\", fontsize=10)\n",
    "\n",
    "        ax2.set_yticks(range(len(target_marker_order)))\n",
    "        ax2.set_yticklabels([word.capitalize() for word in diff_clipped.index], fontsize=15)\n",
    "        ax2.set_title(f\"q-value (FDR ‚â§ {p_threshold})\", fontsize=15, pad=8)\n",
    "\n",
    "        # Colour bar for p-values\n",
    "        cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8, aspect=20)\n",
    "        cbar2.outline.set_visible(False)\n",
    "        cbar2.set_label(\"FDR\", fontsize=10, labelpad=8)\n",
    "        cbar2.set_ticks([0, p_threshold / 2, p_threshold])\n",
    "        cbar2.set_ticklabels([f\"{x:.3f}\" for x in [0, p_threshold / 2, p_threshold]])\n",
    "\n",
    "        # 7. Adjust layout to avoid label clipping\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "        # 8. Save high-resolution heatmap\n",
    "        heatmap_path = os.path.join(visualization_folder, \"wt_vs_tmie_proportion_diff_heatmap\")\n",
    "        plt.savefig(heatmap_path + \".png\", dpi=1200, bbox_inches='tight')\n",
    "        plt.savefig(heatmap_path + \".pdf\", dpi=1200, bbox_inches='tight')\n",
    "        plt.savefig(heatmap_path + \".eps\", format='eps', dpi=1200, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"‚úÖ Integrated heatmap saved: {heatmap_path}\")\n",
    "        print(f\"   - Top panel: proportion difference (red = tmie higher, blue = tmie lower)\")\n",
    "        print(f\"   - Bottom panel: significance p-values (red = significant, white = non-significant)\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No valid X-axis column-difference results, skipping saving and plotting\")\n",
    "\n",
    "print(f\"\\n===== All X-axis column-difference analyses finished! Results path: {comparison_results_folder} =====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
