{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 位置显著性分析主程序\n",
    "\n",
    "本notebook用于分析RNAscope数据中基因表达的位置分布显著性，包括：\n",
    "1. 数据加载和预处理\n",
    "2. 位置分布区间创建\n",
    "3. 蒙特卡洛模拟分析\n",
    "4. 多重比较校正\n",
    "5. 结果可视化和保存\n",
    "\n",
    "**注意**: 本程序专门处理位置分布显著性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模块导入完成！\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "from modules.judge_sig import (\n",
    "    create_position_bins,\n",
    "    two_step_stratified_sample,\n",
    "    monte_carlo_simulation,\n",
    "    x_monte,\n",
    "    correct_grid_pvalues,\n",
    "    plot_corrected_p_heatmap,\n",
    ")\n",
    "\n",
    "print('✅ 模块导入完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根目录: your_pathway/vg_space_mapping/wt/\n",
      "汇总文件夹: your_pathway/vg_space_mapping/wt/summary\n",
      "模拟次数: 10000\n",
      "x分箱数量: 20, y分箱数量 ：10\n",
      "校正方法: fdr\n",
      "成功加载wt数据，共3604行\n",
      "成功加载BX/BY数据，长度分别为: 8, 8\n",
      "去重前记录数: 3604\n",
      "使用所有列进行完全重复行的去重（仅当一行所有信息均相同时才移除）\n",
      "去重后记录数: 3604 (移除了0条完全重复的记录)\n",
      "vg大小平均值: [3088.18315202 1404.93479673]\n",
      "找到5个阳性标记列: ['e_isPositive', 'b_isPositive', 'd_isPositive', 'c_isPositive', 'a_isPositive']\n",
      "找到坐标列: X=e_warpedROIvar1, Y=e_warpedROIvar2\n",
      "x_bins：覆盖(-0.6, 0.6)，共26个分点，基础间距=0.050525\n",
      "y_bins：覆盖(-0.6, 0.6)，共14个分点，基础间距=0.103153\n",
      "BX区间: -0.57 到 0.44\n",
      "BY区间: -0.48 到 0.55\n"
     ]
    }
   ],
   "source": [
    "# 分析参数\n",
    "n_simulations = 10000\n",
    "num_xbins = 20\n",
    "num_ybins = 10\n",
    "correction_method = 'fdr'\n",
    "bx_min = -0.6\n",
    "bx_max = 0.6\n",
    "by_min = -0.6\n",
    "by_max = 0.6\n",
    "\n",
    "cell_num = 0\n",
    "random_num =42\n",
    "\n",
    "sample_type = 'wt'\n",
    "# ----------------------\n",
    "# 设置路径和参数\n",
    "# ----------------------\n",
    "base_folder = 'your_pathway/vg_space_mapping/wt/' \n",
    "summary_folder = os.path.join(base_folder, \"summary\")\n",
    "sample_info_path = os.path.join(summary_folder, \"sample_info.csv\")\n",
    "wt_summary_path = os.path.join(summary_folder, sample_type + \"_summary_all.csv\")\n",
    "results_file_path = os.path.join(summary_folder, 'vg_averageing_labels.csv')\n",
    "vg_size_path = os.path.join(summary_folder, 'vg_size.csv')\n",
    "\n",
    "# 打印配置信息\n",
    "print(f'根目录: {base_folder}')\n",
    "print(f'汇总文件夹: {summary_folder}')\n",
    "print(f'模拟次数: {n_simulations}')\n",
    "print(f'x分箱数量: {num_xbins}, y分箱数量 ：{num_ybins}')\n",
    "print(f'校正方法: {correction_method}')\n",
    "\n",
    "# ----------------------\n",
    "# 数据加载和预处理\n",
    "# ----------------------\n",
    "def load_data():\n",
    "    \"\"\"加载所有必要数据\"\"\"\n",
    "    try:\n",
    "        wt_data = pd.read_csv(wt_summary_path)\n",
    "        print(f\"成功加载{sample_type}数据，共{len(wt_data)}行\")\n",
    "        \n",
    "        results_data = pd.read_csv(results_file_path, header=None)\n",
    "        BX = results_data.iloc[:, 0].values\n",
    "        BY = results_data.iloc[:, 1].values\n",
    "        print(f\"成功加载BX/BY数据，长度分别为: {len(BX)}, {len(BY)}\")\n",
    "        \n",
    "        return wt_data, BX, BY\n",
    "    except Exception as e:\n",
    "        print(f\"数据加载错误: {e}\")\n",
    "        raise\n",
    "\n",
    "# 加载基础数据\n",
    "summary_data, BX, BY = load_data()\n",
    "# 读取并处理WT汇总数据\n",
    "\n",
    "original_count = len(summary_data)\n",
    "print(f\"去重前记录数: {original_count}\")\n",
    "# 去除所有列信息完全重复的行（一行所有信息都相同时才去重）\n",
    "summary_data = summary_data.drop_duplicates(keep='first')\n",
    "print(\"使用所有列进行完全重复行的去重（仅当一行所有信息均相同时才移除）\")\n",
    "deduplicated_count = len(summary_data)\n",
    "removed_count = original_count - deduplicated_count\n",
    "print(f\"去重后记录数: {deduplicated_count} (移除了{removed_count}条完全重复的记录)\")\n",
    "\n",
    "# 读取vg大小数据并计算标准化坐标\n",
    "vg_size = pd.read_csv(vg_size_path, header=None)\n",
    "avg_vg_size = vg_size.mean(axis=0).values\n",
    "print(f\"vg大小平均值: {avg_vg_size}\")\n",
    "\n",
    "# 定义is_positive_cols - 找到所有以_isPositive结尾的列\n",
    "is_positive_cols = [col for col in summary_data.columns if col.endswith('_isPositive')]\n",
    "if not is_positive_cols:\n",
    "    raise ValueError(\"未找到任何以'_isPositive'结尾的列，请检查数据列名\")\n",
    "print(f\"找到{len(is_positive_cols)}个阳性标记列: {is_positive_cols}\")\n",
    "\n",
    "# 查找坐标列\n",
    "x_col = next((col for col in summary_data.columns if col.endswith('warpedROIvar1')), None)\n",
    "y_col = next((col for col in summary_data.columns if col.endswith('warpedROIvar2')), None)\n",
    "\n",
    "if not x_col or not y_col:\n",
    "    missing = []\n",
    "    if not x_col: missing.append(\"warpedROIvar1结尾的列\")\n",
    "    if not y_col: missing.append(\"warpedROIvar2结尾的列\")\n",
    "    raise ValueError(f\"缺少必要的坐标列: {', '.join(missing)}\")\n",
    "\n",
    "print(f\"找到坐标列: X={x_col}, Y={y_col}\")\n",
    "\n",
    "# 计算标准化坐标\n",
    "summary_data['standardized_x'] = summary_data[x_col] / avg_vg_size[0]\n",
    "summary_data['standardized_y'] = summary_data[y_col] / avg_vg_size[1]\n",
    "\n",
    "data = summary_data[['Label'] + is_positive_cols + ['standardized_x', 'standardized_y', 'hasPositive']].copy()\n",
    "\n",
    "if cell_num > 0 :\n",
    "    data = two_step_stratified_sample(data, cell_num, random_num)\n",
    "\n",
    "order_list=[0, 7, 2, 6, 4, 5, 3, 1, 0]\n",
    "BX_ordered = BX[order_list]\n",
    "BY_ordered = BY[order_list]\n",
    "cs = CubicSpline(np.arange(len(BX_ordered)), np.c_[BX_ordered, BY_ordered], \n",
    "                axis=0, bc_type='periodic')\n",
    "t_fine = np.linspace(0, len(BX_ordered)-1, 300)\n",
    "x_fine, y_fine = cs(t_fine).T\n",
    "\n",
    "# 计算BX和BY的边界\n",
    "actual_bx_min, actual_bx_max = x_fine.min(), x_fine.max()\n",
    "actual_by_min, actual_by_max = y_fine.min(), y_fine.max()\n",
    "\n",
    "# 创建区间\n",
    "bx_bins, by_bins = create_position_bins(\n",
    "    actual_bx_min, actual_bx_max,\n",
    "    actual_by_min, actual_by_max,\n",
    "    num_xbins, num_ybins\n",
    ")\n",
    "\n",
    "print(f\"BX区间: {actual_bx_min:.2f} 到 {actual_bx_max:.2f}\")\n",
    "print(f\"BY区间: {actual_by_min:.2f} 到 {actual_by_max:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 开始蒙特卡洛模拟 =====\n",
      "\n",
      "===== 分析 e_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模拟 e_isPositive: 100%|██████████| 10000/10000 [00:08<00:00, 1160.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_isPositive 真实计数总和: 569.0\n",
      "✅ e_isPositive 分析完成\n",
      "\n",
      "===== 分析 b_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模拟 b_isPositive: 100%|██████████| 10000/10000 [00:08<00:00, 1136.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_isPositive 真实计数总和: 509.0\n",
      "✅ b_isPositive 分析完成\n",
      "\n",
      "===== 分析 d_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模拟 d_isPositive: 100%|██████████| 10000/10000 [00:09<00:00, 1093.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_isPositive 真实计数总和: 784.0\n",
      "✅ d_isPositive 分析完成\n",
      "\n",
      "===== 分析 c_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模拟 c_isPositive: 100%|██████████| 10000/10000 [00:08<00:00, 1122.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_isPositive 真实计数总和: 653.0\n",
      "✅ c_isPositive 分析完成\n",
      "\n",
      "===== 分析 a_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模拟 a_isPositive: 100%|██████████| 10000/10000 [00:08<00:00, 1124.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_isPositive 真实计数总和: 1089.0\n",
      "✅ a_isPositive 分析完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== 开始蒙特卡洛模拟 =====\")\n",
    "results = []\n",
    "\n",
    "for col in is_positive_cols:\n",
    "    gene = col.replace('_isPositive', '')\n",
    "    x_col = 'standardized_x'\n",
    "    y_col = 'standardized_y'\n",
    "    \n",
    "    if x_col not in data.columns or y_col not in data.columns:\n",
    "        print(f\"⚠️ 警告: 未找到标准化坐标列，跳过 {col}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n===== 分析 {col} =====\")\n",
    "    print(f\"使用的坐标列: X={x_col}, Y={y_col}\")\n",
    "    \n",
    "    result = monte_carlo_simulation(data, col, x_col, y_col, bx_bins, by_bins, n_simulations, save_base_dir=os.path.join(summary_folder, \"test_monte\"))\n",
    "    \n",
    "    if result is not None:\n",
    "        total_real = np.sum(result['real_counts'])\n",
    "        print(f\"{col} 真实计数总和: {total_real}\")\n",
    "        \n",
    "        if total_real > 0:\n",
    "            result['corrected_p'] = correct_grid_pvalues(result['p_values'], method=correction_method)\n",
    "            results.append(result)\n",
    "            print(f\"✅ {col} 分析完成\")\n",
    "        else:\n",
    "            print(f\"❌ {col} 真实计数总和为0，不添加到结果中\")\n",
    "    else:\n",
    "        print(f\"❌ {col} 分析失败，未生成结果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 保存分析结果 =====\n",
      "已保存计数热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\e_count.png\n",
      "已保存p值热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\e_p.png\n",
      "已保存计数热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\b_count.png\n",
      "已保存p值热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\b_p.png\n",
      "已保存计数热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\d_count.png\n",
      "已保存p值热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\d_p.png\n",
      "已保存计数热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\c_count.png\n",
      "已保存p值热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\c_p.png\n",
      "已保存计数热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\a_count.png\n",
      "已保存p值热图至: your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt\\a_p.png\n",
      "\n",
      "===== 分析完成 =====\n"
     ]
    }
   ],
   "source": [
    "min_count = 0\n",
    "max_count = 0.02\n",
    "if results:\n",
    "    print(\"\\n===== 保存分析结果 =====\")\n",
    "    if cell_num > 0 :\n",
    "        results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_{cell_num}\")\n",
    "        visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_{cell_num}\")\n",
    "    else:\n",
    "        results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}\")\n",
    "        visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "    \n",
    "    for result in results:\n",
    "        gene = result['gene']\n",
    "        np.savetxt(os.path.join(results_folder, f'{gene}_real_counts.csv'), result['real_counts'], delimiter=',', fmt='%d')\n",
    "        np.savetxt(os.path.join(results_folder, f'{gene}_corrected_p.csv'), result['corrected_p'], delimiter=',', fmt='%.6f')\n",
    "        plot_corrected_p_heatmap(result, data, gene, bx_min, bx_max, by_min, by_max, BX, BY, visualization_folder, min_count, max_count)\n",
    "else:\n",
    "    print(\"\\n⚠️ 没有生成任何有效结果\")\n",
    "\n",
    "print(\"\\n===== 分析完成 =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 开始x轴分布蒙特卡洛模拟 =====\n",
      "\n",
      "===== 分析 e_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X轴模拟 e_isPositive: 100%|██████████| 10000/10000 [00:17<00:00, 557.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_isPositive 真实计数总和: 569\n",
      "✅ e_isPositive 分析完成\n",
      "\n",
      "===== 分析 b_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X轴模拟 b_isPositive: 100%|██████████| 10000/10000 [00:17<00:00, 565.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_isPositive 真实计数总和: 509\n",
      "✅ b_isPositive 分析完成\n",
      "\n",
      "===== 分析 d_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X轴模拟 d_isPositive: 100%|██████████| 10000/10000 [00:17<00:00, 563.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_isPositive 真实计数总和: 784\n",
      "✅ d_isPositive 分析完成\n",
      "\n",
      "===== 分析 c_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X轴模拟 c_isPositive: 100%|██████████| 10000/10000 [00:17<00:00, 565.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_isPositive 真实计数总和: 653\n",
      "✅ c_isPositive 分析完成\n",
      "\n",
      "===== 分析 a_isPositive =====\n",
      "使用的坐标列: X=standardized_x, Y=standardized_y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X轴模拟 a_isPositive: 100%|██████████| 10000/10000 [00:17<00:00, 574.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_isPositive 真实计数总和: 1089\n",
      "✅ a_isPositive 分析完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== 开始x轴分布蒙特卡洛模拟 =====\")\n",
    "results = []\n",
    "\n",
    "for col in is_positive_cols:\n",
    "    gene = col.replace('_isPositive', '')\n",
    "    x_col = 'standardized_x'\n",
    "    y_col = 'standardized_y'\n",
    "    \n",
    "    if x_col not in data.columns or y_col not in data.columns:\n",
    "        print(f\"⚠️ 警告: 未找到标准化坐标列，跳过 {col}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n===== 分析 {col} =====\")\n",
    "    print(f\"使用的坐标列: X={x_col}, Y={y_col}\")\n",
    "    \n",
    "    result = x_monte(\n",
    "        data, col, x_col, \n",
    "        bx_bins, n_simulations\n",
    "    )\n",
    "    \n",
    "    if result is not None:\n",
    "        total_real = np.sum(result['real_counts'])\n",
    "        print(f\"{col} 真实计数总和: {total_real}\")\n",
    "        \n",
    "        if total_real > 0:\n",
    "            result['corrected_p'] = correct_grid_pvalues(result['p_values'], method=correction_method)\n",
    "            results.append(result)\n",
    "            print(f\"✅ {col} 分析完成\")\n",
    "        else:\n",
    "            print(f\"❌ {col} 真实计数总和为0，不添加到结果中\")\n",
    "    else:\n",
    "        print(f\"❌ {col} 分析失败，未生成结果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 1. 整合并保存所有Marker的X轴数据 =====\n",
      "✅ 已保存所有marker真实计数：all_markers_real_counts.csv\n",
      "✅ 已保存所有marker校正后p值：all_markers_corrected_p.csv\n",
      "✅ 已保存x轴分bin信息：x_axis_bin_info.csv\n"
     ]
    }
   ],
   "source": [
    "min_count = 0\n",
    "max_count = 0.1\n",
    "p_value_threshold = 0.05  # 显著性阈值\n",
    "# -------------------------- 关键：定义目标Marker顺序 --------------------------\n",
    "target_marker_order = ['d', 'e', 'b', 'a', 'c']  # 从上到下的顺序\n",
    "\n",
    "if results:\n",
    "    print(\"\\n===== 1. 整合并保存所有Marker的X轴数据 =====\")\n",
    "    # 1.1 创建带_xbins的结果文件夹（延续之前的路径规则）\n",
    "    if cell_num > 0 :\n",
    "        results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_{cell_num}_xbins\")\n",
    "        visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_{cell_num}_xbins\")\n",
    "    else:\n",
    "        results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_xbins\")\n",
    "        visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_xbins\")\n",
    "    os.makedirs(results_folder, exist_ok=True)\n",
    "    os.makedirs(visualization_folder, exist_ok=True)\n",
    "\n",
    "    # 1.2 提取x轴分bin边界（所有marker共用同一套x bins，取第一个有效结果的x bins逻辑）\n",
    "    x_bin_edges = np.linspace(BX.min(), BX.max(), num_xbins+1)  # 直接使用原x轴分bin边界\n",
    "    x_bin_labels = [f\"Bin{i+1}\\n[{x_bin_edges[i]:.2f}-{x_bin_edges[i+1]:.2f}]\" for i in range(len(x_bin_edges)-1)]\n",
    "    x_bin_num = len(x_bin_labels)  # x轴总bin数\n",
    "\n",
    "    # 1.3 整合所有marker的real_counts和corrected_p\n",
    "    # 初始化整合DataFrame（行=marker，列=x bin）\n",
    "    marker_list = []\n",
    "    real_counts_all = []\n",
    "    corrected_p_all = []\n",
    "\n",
    "    # ---------- 1. 计算 20 个 bin 索引 ----------\n",
    "    min_bin_idx  = np.digitize(x_fine.min(), bx_bins) - 1\n",
    "    max_bin_idx  = np.digitize(x_fine.max(), bx_bins) - 1\n",
    "    zero_bin_idx  = np.digitize(0, bx_bins) - 1\n",
    "    x_bins_indices = np.arange(min_bin_idx, min_bin_idx + 20)   # 固定 20 个\n",
    "    x_offsets = x_bins_indices - zero_bin_idx                 # 相对 0 的偏移量\n",
    "\n",
    "    # ---------- 2. 以 5 为步长、以 0 为中心，只在现有 20 个偏移量里挑 ----------\n",
    "    step = 5\n",
    "    low  = int(np.floor(x_offsets.min() / step) * step)\n",
    "    high = int(np.ceil(x_offsets.max() / step) * step)\n",
    "    tick_labels = np.arange(low, high + 1, step)              # 5 的倍数\n",
    "    tick_labels = tick_labels[np.isin(tick_labels, x_offsets)]  # 必存在\n",
    "\n",
    "    # ---------- 3. 对应绘图位置 ----------\n",
    "    tick_positions = [np.where(x_offsets == lab)[0][0] for lab in tick_labels]\n",
    "\n",
    "    for result in results:\n",
    "        marker = result['gene']\n",
    "        rc = result['real_counts']  # 1D数组（x bin数）\n",
    "        cp = result['corrected_p']  # 1D数组（x bin数）\n",
    "        \n",
    "        rc = rc[min_bin_idx:max_bin_idx]\n",
    "        cp = cp[min_bin_idx:max_bin_idx]\n",
    "        marker_list.append(marker)\n",
    "        real_counts_all.append(rc)\n",
    "        corrected_p_all.append(cp)\n",
    "\n",
    "    # 1.4 保存整合数据（CSV格式，便于后续读取和分析）\n",
    "    # 保存真实计数（marker×x bin）\n",
    "    rc_df = pd.DataFrame(real_counts_all, index=marker_list, columns=[f\"X_Bin{i+1}\" for i in range(num_xbins)])\n",
    "    rc_df.index.name = \"Marker\"\n",
    "    rc_df.to_csv(os.path.join(results_folder, \"all_markers_real_counts.csv\"), index=True)\n",
    "    print(f\"✅ 已保存所有marker真实计数：all_markers_real_counts.csv\")\n",
    "\n",
    "    # 保存校正后p值（marker×x bin）\n",
    "    cp_df = pd.DataFrame(corrected_p_all, index=marker_list, columns=[f\"X_Bin{i+1}\" for i in range(num_xbins)])\n",
    "    cp_df.index.name = \"Marker\"\n",
    "    cp_df.to_csv(os.path.join(results_folder, \"all_markers_corrected_p.csv\"), index=True)\n",
    "    print(f\"✅ 已保存所有marker校正后p值：all_markers_corrected_p.csv\")\n",
    "\n",
    "    # 保存x轴分bin信息（便于后续绘图/解读）\n",
    "    x_bin_info = pd.DataFrame({\n",
    "        \"Bin_Index\": range(1, num_xbins+1),\n",
    "        \"Bin_Left\": BX.min(),\n",
    "        \"Bin_Right\": BX.max()\n",
    "    })\n",
    "    x_bin_info.to_csv(os.path.join(results_folder, \"x_axis_bin_info.csv\"), index=False)\n",
    "    print(f\"✅ 已保存x轴分bin信息：x_axis_bin_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 2. 绘制所有Marker整合热图 =====\n",
      "✅ 已保存所有marker整合热图：your_pathway/vg_space_mapping/wt/summary\\grid_visualizations_wt_xbins\\all_markers_xbin_combined_heatmap\n",
      "\n",
      "===== 分析完成 =====\n"
     ]
    }
   ],
   "source": [
    "min_count = 0\n",
    "max_count = 0.1\n",
    "p_value_threshold = 0.05  # 显著性阈值\n",
    "# -------------------------- 关键：定义目标Marker顺序 --------------------------\n",
    "target_marker_order = ['d', 'e', 'b', 'a', 'c']  # 从上到下的顺序\n",
    "if cell_num > 0 :\n",
    "    results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_{cell_num}_xbins\")\n",
    "    visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_{cell_num}_xbins\")\n",
    "else:\n",
    "    results_folder = os.path.join(summary_folder, f\"grid_pvalues_{sample_type}_xbins\")\n",
    "    visualization_folder = os.path.join(summary_folder, f\"grid_visualizations_{sample_type}_xbins\")\n",
    "    \n",
    "if results:\n",
    "    rc_df = pd.read_csv(os.path.join(results_folder, \"all_markers_real_counts.csv\"), header=0, index_col = 0)\n",
    "    cp_df = pd.read_csv(os.path.join(results_folder, \"all_markers_corrected_p.csv\"), header=0, index_col = 0)\n",
    "    x_bin_info = pd.read_csv(os.path.join(results_folder, \"x_axis_bin_info.csv\"), header=0, index_col = 0)\n",
    "    # -------------------------- 2. 绘制整合热图（所有marker合并为一张） --------------------------\n",
    "    print(\"\\n===== 2. 绘制所有Marker整合热图 =====\")\n",
    "    # -------------------------- 关键修改1：筛选并按目标顺序重排数据 --------------------------\n",
    "    # 1. 筛选：只保留目标Marker的数据（排除不在目标列表中的Marker）\n",
    "    rc_df_filtered = rc_df.loc[rc_df.index.isin(target_marker_order)]  # 计数数据筛选\n",
    "    cp_df_filtered = cp_df.loc[cp_df.index.isin(target_marker_order)]  # p值数据筛选\n",
    "    \n",
    "    # 2. 重排序：按target_marker_order的顺序调整行索引（核心步骤）\n",
    "    rc_df_ordered = rc_df_filtered.reindex(target_marker_order)  # 计数数据按目标顺序排列\n",
    "    cp_df_ordered = cp_df_filtered.reindex(target_marker_order)  # p值数据按目标顺序排列\n",
    "    \n",
    "    # 3. 检查是否有缺失（可选：避免目标Marker无数据导致空图）\n",
    "    missing_markers = [m for m in target_marker_order if m not in rc_df_ordered.index]\n",
    "    if missing_markers:\n",
    "        print(f\"⚠️ 以下Marker无数据，已跳过：{missing_markers}\")\n",
    "    if rc_df_ordered.empty:\n",
    "        print(\"⚠️ 无有效Marker数据，跳过绘图\")\n",
    "    else:\n",
    "        # 2.1 数据预处理（基于重排序后的数据）\n",
    "        rc_normalized = rc_df_ordered.div(rc_df_ordered.sum(axis=1), axis=0)  # 计数归一化\n",
    "        cp_clipped = cp_df_ordered.clip(upper=p_value_threshold)  # p值截断（避免颜色溢出）\n",
    "\n",
    "        # 2.2 创建画布（2个子图：上=计数热图，下=p值热图）\n",
    "        # 高度随有效Marker数量自适应（rc_df_ordered.shape[0]即有效Marker数）\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 1*rc_df_ordered.shape[0]))\n",
    "        fig.suptitle(f\"All Markers - X-axis Bins Analysis (Sample: {sample_type})\", fontsize=14, y=0.98)\n",
    "\n",
    "        # 2.3 绘制「计数比例热图」（上子图，基于重排序数据）\n",
    "        im1 = ax1.imshow(rc_normalized.values, cmap='Blues', aspect='auto', vmin=min_count, vmax=max_count)\n",
    "        # 设置坐标轴标签（yticks用重排序后的Marker列表）\n",
    "        ax1.set_xticks(tick_positions)\n",
    "        ax1.set_xticklabels(tick_labels, fontsize=15)\n",
    "        ax1.set_xlabel(\"offset from border\", fontsize=15)\n",
    "        \n",
    "        # -------------------------- 关键修改2：y轴标签用重排序后的Marker --------------------------\n",
    "        ax1.set_yticks(range(len(rc_df_ordered)))  # y轴刻度位置（对应重排序后的行数）\n",
    "        ax1.set_yticklabels([word.capitalize() for word in rc_df_ordered.index], fontsize=15)  # y轴标签=目标顺序的Marker\n",
    "        ax1.set_title(\"Positive Cell Proportion\", fontsize=15, pad=8)\n",
    "\n",
    "        # 添加计数热图颜色条\n",
    "        cbar1 = plt.colorbar(im1, ax=ax1, shrink=0.8, aspect=20)\n",
    "        cbar1.outline.set_visible(False)\n",
    "        cbar1.set_label(\"Cell Proportion\", fontsize=15, labelpad=8)\n",
    "        cbar1.set_ticks([min_count, (min_count+max_count)/2, max_count])\n",
    "        cbar1.set_ticklabels([f\"{x:.2f}\" for x in [min_count, (min_count+max_count)/2, max_count]], fontsize=12)\n",
    "\n",
    "        # 2.4 绘制「校正后p值热图」（下子图，基于重排序数据）\n",
    "        im2 = ax2.imshow(cp_clipped.values, cmap='Reds_r', aspect='auto', vmin=0, vmax=p_value_threshold)\n",
    "        # 设置坐标轴标签（y轴与上子图一致，保持顺序统一）\n",
    "        ax2.set_xticks(tick_positions)\n",
    "        ax2.set_xticklabels(tick_labels, fontsize=15)\n",
    "        ax2.set_xlabel(\"offset from border\", fontsize=15)\n",
    "        \n",
    "        # -------------------------- 关键修改3：p值图y轴与计数图保持一致顺序 --------------------------\n",
    "        ax2.set_yticks(range(len(cp_df_ordered)))  # y轴刻度位置（对应重排序后的行数）\n",
    "        ax2.set_yticklabels([word.capitalize() for word in cp_df_ordered.index], fontsize=15)  # y轴标签=目标顺序的Marker\n",
    "        ax2.set_title(f\"q-value (FDR, cutoff at {p_value_threshold})\", fontsize=15, pad=8)\n",
    "\n",
    "        # 添加p值热图颜色条\n",
    "        cbar2 = plt.colorbar(im2, ax=ax2, shrink=0.8, aspect=20)\n",
    "        cbar2.outline.set_visible(False)\n",
    "        cbar2.set_label(\"FDR\", fontsize=10, labelpad=8)\n",
    "        cbar2.set_ticks([0, p_value_threshold/2, p_value_threshold])\n",
    "        cbar2.set_ticklabels([f\"{x:.2f}\" for x in [0, p_value_threshold/2, p_value_threshold]], fontsize=10)\n",
    "\n",
    "        # 2.5 调整布局（避免标签重叠）\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # 预留顶部标题空间\n",
    "\n",
    "        # 2.6 保存整合热图\n",
    "        heatmap_path = os.path.join(visualization_folder, \"all_markers_xbin_combined_heatmap\")\n",
    "        plt.savefig(heatmap_path + \".png\", dpi=1200, bbox_inches='tight')\n",
    "        plt.savefig(heatmap_path + \".pdf\", dpi=1200, bbox_inches='tight')\n",
    "        plt.savefig(heatmap_path + \".eps\", format = 'eps', dpi=1200, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(f\"✅ 已保存所有marker整合热图：{heatmap_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️ 没有生成任何有效结果，跳过数据保存和绘图\")\n",
    "\n",
    "print(\"\\n===== 分析完成 =====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_color = {'d': \"#E3776B\",'e': \"#9AA218\",'b': \"#1BAF73\",'a': \"#26A2D5\",'c': \"#B374AD\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 位置显著性分析完成！\n",
    "\n",
    "所有分析步骤已完成，包括：\n",
    "- ✅ 数据加载和预处理\n",
    "- ✅ 位置分布区间创建\n",
    "- ✅ 蒙特卡洛模拟分析\n",
    "- ✅ 多重比较校正\n",
    "- ✅ 结果保存和可视化\n",
    "\n",
    "**生成的文件**:\n",
    "- 位置显著性结果CSV文件\n",
    "- 热图可视化图片\n",
    "\n",
    "**如果遇到问题**:\n",
    "1. 检查模块导入是否正确\n",
    "2. 验证数据文件路径\n",
    "3. 查看错误信息进行调试\n",
    "\n",
    "**下一步**: 可以查看生成的结果文件和图片，或进行其他数据分析。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
