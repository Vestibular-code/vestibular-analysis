{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNAscope 数据汇总处理程序\n",
    "\n",
    "本notebook用于处理RNAscope数据，将每个sam_name的多个marker文件合并成一个汇总文件。\n",
    "\n",
    "主要功能：\n",
    "1. 读取sample_info.csv获取sam_name列表\n",
    "2. 为每个sam_name合并对应的summary文件\n",
    "3. 添加marker前缀并处理列名\n",
    "4. 计算hasPositive列\n",
    "5. 保存合并后的汇总文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模块导入完成！\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的模块\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "print('模块导入完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根目录: yourpathway/vg_space_mapping/wt/\n",
      "汇总文件夹: yourpathway/vg_space_mapping/wt/summary\n",
      "样本信息文件: yourpathway/vg_space_mapping/wt/summary\\sample_info.csv\n"
     ]
    }
   ],
   "source": [
    "# 设置路径和初始化变量\n",
    "base_folder = 'yourpathway/vg_space_mapping/wt/'  # 当前工作目录作为根目录\n",
    "summary_folder = os.path.join(base_folder, \"summary\")\n",
    "sample_info_path = os.path.join(summary_folder, \"sample_info.csv\")\n",
    "\n",
    "print(f'根目录: {base_folder}')\n",
    "print(f'汇总文件夹: {summary_folder}')\n",
    "print(f'样本信息文件: {sample_info_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功读取样本信息文件，找到 2 个唯一的sam_name\n",
      "sam_name列表: ['wt', 'tmie']\n"
     ]
    }
   ],
   "source": [
    "# 读取 sample_info.csv 文件获取 samName\n",
    "try:\n",
    "    sample_info_df = pd.read_csv(sample_info_path)\n",
    "    # 获取唯一的 samName 列表\n",
    "    sam_names = sample_info_df['sam_name'].unique()\n",
    "    print(f'✅ 成功读取样本信息文件，找到 {len(sam_names)} 个唯一的sam_name')\n",
    "    print(f'sam_name列表: {list(sam_names)}')\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ 错误：未找到文件 {sample_info_path}\")\n",
    "    print(\"请检查文件路径是否正确\")\n",
    "    sam_names = []\n",
    "except Exception as e:\n",
    "    print(f\"❌ 读取文件时发生错误: {e}\")\n",
    "    sam_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "汇总文件夹中共有 14 个CSV文件\n",
      "前10个CSV文件:\n",
      "  1. sample_info.csv\n",
      "  2. tmie_summary_e.csv\n",
      "  3. tmie_summary_b.csv\n",
      "  4. tmie_summary_d.csv\n",
      "  5. tmie_summary_c.csv\n",
      "  6. tmie_summary_a.csv\n",
      "  7. vg_averageing_labels.csv\n",
      "  8. vg_size.csv\n",
      "  9. wt_summary_all.csv\n",
      "  10. wt_summary_e.csv\n",
      "  ... 还有 4 个文件\n"
     ]
    }
   ],
   "source": [
    "# 检查汇总文件夹中的文件\n",
    "if os.path.exists(summary_folder):\n",
    "    summary_files = os.listdir(summary_folder)\n",
    "    csv_files = [f for f in summary_files if f.endswith('.csv')]\n",
    "    print(f'汇总文件夹中共有 {len(csv_files)} 个CSV文件')\n",
    "    print('前10个CSV文件:')\n",
    "    for i, file in enumerate(csv_files[:10]):\n",
    "        print(f'  {i+1}. {file}')\n",
    "    if len(csv_files) > 10:\n",
    "        print(f'  ... 还有 {len(csv_files) - 10} 个文件')\n",
    "else:\n",
    "    print(f'❌ 汇总文件夹不存在: {summary_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理函数定义完成！\n"
     ]
    }
   ],
   "source": [
    "def process_sam_name(sam_name, summary_folder):\n",
    "    \"\"\"处理单个sam_name的数据合并\"\"\"\n",
    "    print(f\"\\n正在处理 sam_name: {sam_name}\")\n",
    "    \n",
    "    # 获取当前samName对应的所有summary文件，排除以_all.csv结尾的文件\n",
    "    sam_files = [f for f in os.listdir(summary_folder) \n",
    "                  if f.startswith(f\"{sam_name}_summary_\") and not f.endswith(\"_all.csv\")]\n",
    "    \n",
    "    if not sam_files:\n",
    "        print(f\"⚠️ 警告：未找到sam_name {sam_name} 对应的文件\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"找到 {len(sam_files)} 个相关文件:\")\n",
    "    for file in sam_files:\n",
    "        print(f\"  - {file}\")\n",
    "    \n",
    "    # 初始化一个列表来存储所有数据框\n",
    "    dataframes = []\n",
    "    \n",
    "    # 读取每个文件\n",
    "    for file in sam_files:\n",
    "        file_path = os.path.join(summary_folder, file)\n",
    "        try:\n",
    "            # 从文件名中提取marker名称\n",
    "            parts = file.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                marker = parts[2].replace('.csv', '')\n",
    "            else:\n",
    "                print(f\"⚠️ 警告：文件名格式不符合预期 {file}，跳过提取marker。\")\n",
    "                marker = \"\"\n",
    "\n",
    "            # 读取CSV文件\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # 确保数据框中有Label列\n",
    "            if 'Label' not in df.columns:\n",
    "                print(f\"⚠️ 警告：文件 {file_path} 中没有Label列，跳过。\")\n",
    "                continue\n",
    "            \n",
    "            # 为除Label外的所有列添加marker前缀 (如果marker不为空)\n",
    "            if marker:\n",
    "                rename_dict = {col: f\"{marker}_{col}\" for col in df.columns if col != 'Label'}\n",
    "                df = df.rename(columns=rename_dict)\n",
    "                print(f\"    为 {file} 添加了marker前缀: {marker}\")\n",
    "            \n",
    "            dataframes.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 读取文件 {file_path} 时发生错误: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not dataframes:\n",
    "        print(f\"❌ 没有为 sam_name: {sam_name} 找到有效数据\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"成功读取 {len(dataframes)} 个数据文件\")\n",
    "    \n",
    "    # 使用reduce函数将所有数据框按Label列横向合并\n",
    "    if len(dataframes) > 1:\n",
    "        final_df = reduce(\n",
    "            lambda left, right: pd.merge(left, right, on='Label', how='outer'),\n",
    "            dataframes\n",
    "        )\n",
    "        print(f\"合并完成，最终数据框形状: {final_df.shape}\")\n",
    "    else:\n",
    "        final_df = dataframes[0]\n",
    "        print(f\"只有一个数据框，无需合并，形状: {final_df.shape}\")\n",
    "    \n",
    "    # 区分处理isPositive列和其他列的缺失值\n",
    "    # 首先获取所有isPositive列\n",
    "    is_positive_cols = [col for col in final_df.columns if col.endswith('_isPositive')]\n",
    "    # 其他列（排除Label和isPositive列）\n",
    "    other_cols = [col for col in final_df.columns if col not in is_positive_cols and col != 'Label']\n",
    "    \n",
    "    # 对isPositive列的缺失值填充0\n",
    "    if is_positive_cols:\n",
    "        final_df[is_positive_cols] = final_df[is_positive_cols].fillna(-1)\n",
    "        print(f\"已将 {len(is_positive_cols)} 个isPositive列的缺失值填充为-1\")\n",
    "    \n",
    "    # 对其他列的缺失值填充-1\n",
    "    if other_cols:\n",
    "        final_df[other_cols] = final_df[other_cols].fillna(-1)\n",
    "        print(f\"已将 {len(other_cols)} 个其他列的缺失值填充为-1\")\n",
    "    \n",
    "    # 添加hasPositive列\n",
    "    if is_positive_cols:\n",
    "        print(f\"找到 {len(is_positive_cols)} 个isPositive列: {is_positive_cols}\")\n",
    "        # 确保参与计算的列是数值类型\n",
    "        for col in is_positive_cols:\n",
    "            if col in final_df.columns:\n",
    "                final_df[col] = pd.to_numeric(final_df[col], errors='coerce').fillna(0)  # 这里也改为填充0\n",
    "\n",
    "        # 只要有一个isPositive列的值为1，hasPositive就为1，否则为0\n",
    "        final_df['hasPositive'] = final_df[is_positive_cols].apply(\n",
    "            lambda row: 1 if (row == 1).any() else 0, axis=1\n",
    "        )\n",
    "        print(\"已计算hasPositive列\")\n",
    "    else:\n",
    "        final_df['hasPositive'] = 0\n",
    "        print(\"未找到isPositive列，hasPositive列设为全0\")\n",
    "    \n",
    "    # 在保存前删除所有完全重复的行\n",
    "    original_rows = len(final_df)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "    removed_rows = original_rows - len(final_df)\n",
    "    if removed_rows > 0:\n",
    "        print(f\"删除了 {removed_rows} 行重复数据\")\n",
    "    \n",
    "    # 保存合并后的数据框\n",
    "    output_file_name = f\"{sam_name}_summary_all.csv\"\n",
    "    output_file_path = os.path.join(summary_folder, output_file_name)\n",
    "    final_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"✅ 汇总表格已保存到 {output_file_path}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"处理函数定义完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 开始处理所有sam_name的数据 =====\n",
      "\n",
      "正在处理 sam_name: wt\n",
      "找到 5 个相关文件:\n",
      "  - wt_summary_e.csv\n",
      "  - wt_summary_b.csv\n",
      "  - wt_summary_d.csv\n",
      "  - wt_summary_c.csv\n",
      "  - wt_summary_a.csv\n",
      "    为 wt_summary_e.csv 添加了marker前缀: e\n",
      "    为 wt_summary_b.csv 添加了marker前缀: b\n",
      "    为 wt_summary_d.csv 添加了marker前缀: d\n",
      "    为 wt_summary_c.csv 添加了marker前缀: c\n",
      "    为 wt_summary_a.csv 添加了marker前缀: a\n",
      "成功读取 5 个数据文件\n",
      "合并完成，最终数据框形状: (3604, 31)\n",
      "已将 5 个isPositive列的缺失值填充为-1\n",
      "已将 25 个其他列的缺失值填充为-1\n",
      "找到 5 个isPositive列: ['e_isPositive', 'b_isPositive', 'd_isPositive', 'c_isPositive', 'a_isPositive']\n",
      "已计算hasPositive列\n",
      "✅ 汇总表格已保存到 yourpathway/vg_space_mapping/wt/summary\\wt_summary_all.csv\n",
      "\n",
      "正在处理 sam_name: tmie\n",
      "找到 5 个相关文件:\n",
      "  - tmie_summary_e.csv\n",
      "  - tmie_summary_b.csv\n",
      "  - tmie_summary_d.csv\n",
      "  - tmie_summary_c.csv\n",
      "  - tmie_summary_a.csv\n",
      "    为 tmie_summary_e.csv 添加了marker前缀: e\n",
      "    为 tmie_summary_b.csv 添加了marker前缀: b\n",
      "    为 tmie_summary_d.csv 添加了marker前缀: d\n",
      "    为 tmie_summary_c.csv 添加了marker前缀: c\n",
      "    为 tmie_summary_a.csv 添加了marker前缀: a\n",
      "成功读取 5 个数据文件\n",
      "合并完成，最终数据框形状: (2090, 31)\n",
      "已将 5 个isPositive列的缺失值填充为-1\n",
      "已将 25 个其他列的缺失值填充为-1\n",
      "找到 5 个isPositive列: ['e_isPositive', 'b_isPositive', 'd_isPositive', 'c_isPositive', 'a_isPositive']\n",
      "已计算hasPositive列\n",
      "✅ 汇总表格已保存到 yourpathway/vg_space_mapping/wt/summary\\tmie_summary_all.csv\n",
      "\n",
      "🎉 所有 sam_name 的数据处理完成！\n",
      "成功处理: 2/2 个sam_name\n"
     ]
    }
   ],
   "source": [
    "# 执行数据处理\n",
    "if len(sam_names) > 0:\n",
    "    print(\"===== 开始处理所有sam_name的数据 =====\")\n",
    "    \n",
    "    success_count = 0\n",
    "    for sam_name in sam_names:\n",
    "        if process_sam_name(sam_name, summary_folder):\n",
    "            success_count += 1\n",
    "    \n",
    "    print(f\"\\n🎉 所有 sam_name 的数据处理完成！\")\n",
    "    print(f\"成功处理: {success_count}/{len(sam_names)} 个sam_name\")\n",
    "else:\n",
    "    print(\"❌ 没有找到sam_name，无法进行处理\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 检查生成的文件 =====\n",
      "找到 2 个汇总文件:\n",
      "  - tmie_summary_all.csv (933631 bytes)\n",
      "    形状: (2090, 32), 列数: 32\n",
      "    列名: ['Label', 'e_pos_X', 'e_pos_Y', 'e_warpedROIvar1', 'e_warpedROIvar2']...\n",
      "  - wt_summary_all.csv (1581245 bytes)\n",
      "    形状: (3604, 32), 列数: 32\n",
      "    列名: ['Label', 'e_pos_X', 'e_pos_Y', 'e_warpedROIvar1', 'e_warpedROIvar2']...\n"
     ]
    }
   ],
   "source": [
    "# 检查生成的文件\n",
    "print(\"\\n===== 检查生成的文件 =====\")\n",
    "if os.path.exists(summary_folder):\n",
    "    all_files = [f for f in os.listdir(summary_folder) if f.endswith('_all.csv')]\n",
    "    if all_files:\n",
    "        print(f\"找到 {len(all_files)} 个汇总文件:\")\n",
    "        for file in all_files:\n",
    "            file_path = os.path.join(summary_folder, file)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"  - {file} ({file_size} bytes)\")\n",
    "            \n",
    "            # 显示文件内容预览\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                print(f\"    形状: {df.shape}, 列数: {len(df.columns)}\")\n",
    "                print(f\"    列名: {list(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    无法读取文件内容: {e}\")\n",
    "    else:\n",
    "        print(\"未找到任何汇总文件\")\n",
    "else:\n",
    "    print(f\"汇总文件夹不存在: {summary_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 数据处理完成！\n",
    "\n",
    "所有sam_name的数据已成功处理并合并。\n",
    "\n",
    "**处理结果**:\n",
    "- 每个sam_name生成了一个 `{sam_name}_summary_all.csv` 文件\n",
    "- 所有marker数据按Label列合并\n",
    "- 添加了hasPositive列标识阳性结果\n",
    "- 重复数据已自动清理\n",
    "\n",
    "**下一步**: 可以使用生成的文件进行后续分析或可视化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
