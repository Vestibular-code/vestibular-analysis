{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNAscope æ•°æ®æ±‡æ€»å¤„ç†ç¨‹åº\n",
    "\n",
    "æœ¬notebookç”¨äºå¤„ç†RNAscopeæ•°æ®ï¼Œå°†æ¯ä¸ªsam_nameçš„å¤šä¸ªmarkeræ–‡ä»¶åˆå¹¶æˆä¸€ä¸ªæ±‡æ€»æ–‡ä»¶ã€‚\n",
    "\n",
    "ä¸»è¦åŠŸèƒ½ï¼š\n",
    "1. è¯»å–sample_info.csvè·å–sam_nameåˆ—è¡¨\n",
    "2. ä¸ºæ¯ä¸ªsam_nameåˆå¹¶å¯¹åº”çš„summaryæ–‡ä»¶\n",
    "3. æ·»åŠ markerå‰ç¼€å¹¶å¤„ç†åˆ—å\n",
    "4. è®¡ç®—hasPositiveåˆ—\n",
    "5. ä¿å­˜åˆå¹¶åçš„æ±‡æ€»æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å—å¯¼å…¥å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„æ¨¡å—\n",
    "import os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "print('æ¨¡å—å¯¼å…¥å®Œæˆï¼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¹ç›®å½•: yourpathway/vg_space_mapping/wt/\n",
      "æ±‡æ€»æ–‡ä»¶å¤¹: yourpathway/vg_space_mapping/wt/summary\n",
      "æ ·æœ¬ä¿¡æ¯æ–‡ä»¶: yourpathway/vg_space_mapping/wt/summary\\sample_info.csv\n"
     ]
    }
   ],
   "source": [
    "# è®¾ç½®è·¯å¾„å’Œåˆå§‹åŒ–å˜é‡\n",
    "base_folder = 'yourpathway/vg_space_mapping/wt/'  # å½“å‰å·¥ä½œç›®å½•ä½œä¸ºæ ¹ç›®å½•\n",
    "summary_folder = os.path.join(base_folder, \"summary\")\n",
    "sample_info_path = os.path.join(summary_folder, \"sample_info.csv\")\n",
    "\n",
    "print(f'æ ¹ç›®å½•: {base_folder}')\n",
    "print(f'æ±‡æ€»æ–‡ä»¶å¤¹: {summary_folder}')\n",
    "print(f'æ ·æœ¬ä¿¡æ¯æ–‡ä»¶: {sample_info_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸè¯»å–æ ·æœ¬ä¿¡æ¯æ–‡ä»¶ï¼Œæ‰¾åˆ° 2 ä¸ªå”¯ä¸€çš„sam_name\n",
      "sam_nameåˆ—è¡¨: ['wt', 'tmie']\n"
     ]
    }
   ],
   "source": [
    "# è¯»å– sample_info.csv æ–‡ä»¶è·å– samName\n",
    "try:\n",
    "    sample_info_df = pd.read_csv(sample_info_path)\n",
    "    # è·å–å”¯ä¸€çš„ samName åˆ—è¡¨\n",
    "    sam_names = sample_info_df['sam_name'].unique()\n",
    "    print(f'âœ… æˆåŠŸè¯»å–æ ·æœ¬ä¿¡æ¯æ–‡ä»¶ï¼Œæ‰¾åˆ° {len(sam_names)} ä¸ªå”¯ä¸€çš„sam_name')\n",
    "    print(f'sam_nameåˆ—è¡¨: {list(sam_names)}')\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°æ–‡ä»¶ {sample_info_path}\")\n",
    "    print(\"è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®\")\n",
    "    sam_names = []\n",
    "except Exception as e:\n",
    "    print(f\"âŒ è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "    sam_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ±‡æ€»æ–‡ä»¶å¤¹ä¸­å…±æœ‰ 14 ä¸ªCSVæ–‡ä»¶\n",
      "å‰10ä¸ªCSVæ–‡ä»¶:\n",
      "  1. sample_info.csv\n",
      "  2. tmie_summary_e.csv\n",
      "  3. tmie_summary_b.csv\n",
      "  4. tmie_summary_d.csv\n",
      "  5. tmie_summary_c.csv\n",
      "  6. tmie_summary_a.csv\n",
      "  7. vg_averageing_labels.csv\n",
      "  8. vg_size.csv\n",
      "  9. wt_summary_all.csv\n",
      "  10. wt_summary_e.csv\n",
      "  ... è¿˜æœ‰ 4 ä¸ªæ–‡ä»¶\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥æ±‡æ€»æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶\n",
    "if os.path.exists(summary_folder):\n",
    "    summary_files = os.listdir(summary_folder)\n",
    "    csv_files = [f for f in summary_files if f.endswith('.csv')]\n",
    "    print(f'æ±‡æ€»æ–‡ä»¶å¤¹ä¸­å…±æœ‰ {len(csv_files)} ä¸ªCSVæ–‡ä»¶')\n",
    "    print('å‰10ä¸ªCSVæ–‡ä»¶:')\n",
    "    for i, file in enumerate(csv_files[:10]):\n",
    "        print(f'  {i+1}. {file}')\n",
    "    if len(csv_files) > 10:\n",
    "        print(f'  ... è¿˜æœ‰ {len(csv_files) - 10} ä¸ªæ–‡ä»¶')\n",
    "else:\n",
    "    print(f'âŒ æ±‡æ€»æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {summary_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "def process_sam_name(sam_name, summary_folder):\n",
    "    \"\"\"å¤„ç†å•ä¸ªsam_nameçš„æ•°æ®åˆå¹¶\"\"\"\n",
    "    print(f\"\\næ­£åœ¨å¤„ç† sam_name: {sam_name}\")\n",
    "    \n",
    "    # è·å–å½“å‰samNameå¯¹åº”çš„æ‰€æœ‰summaryæ–‡ä»¶ï¼Œæ’é™¤ä»¥_all.csvç»“å°¾çš„æ–‡ä»¶\n",
    "    sam_files = [f for f in os.listdir(summary_folder) \n",
    "                  if f.startswith(f\"{sam_name}_summary_\") and not f.endswith(\"_all.csv\")]\n",
    "    \n",
    "    if not sam_files:\n",
    "        print(f\"âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°sam_name {sam_name} å¯¹åº”çš„æ–‡ä»¶\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"æ‰¾åˆ° {len(sam_files)} ä¸ªç›¸å…³æ–‡ä»¶:\")\n",
    "    for file in sam_files:\n",
    "        print(f\"  - {file}\")\n",
    "    \n",
    "    # åˆå§‹åŒ–ä¸€ä¸ªåˆ—è¡¨æ¥å­˜å‚¨æ‰€æœ‰æ•°æ®æ¡†\n",
    "    dataframes = []\n",
    "    \n",
    "    # è¯»å–æ¯ä¸ªæ–‡ä»¶\n",
    "    for file in sam_files:\n",
    "        file_path = os.path.join(summary_folder, file)\n",
    "        try:\n",
    "            # ä»æ–‡ä»¶åä¸­æå–markeråç§°\n",
    "            parts = file.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                marker = parts[2].replace('.csv', '')\n",
    "            else:\n",
    "                print(f\"âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶åæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ {file}ï¼Œè·³è¿‡æå–markerã€‚\")\n",
    "                marker = \"\"\n",
    "\n",
    "            # è¯»å–CSVæ–‡ä»¶\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # ç¡®ä¿æ•°æ®æ¡†ä¸­æœ‰Labelåˆ—\n",
    "            if 'Label' not in df.columns:\n",
    "                print(f\"âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶ {file_path} ä¸­æ²¡æœ‰Labelåˆ—ï¼Œè·³è¿‡ã€‚\")\n",
    "                continue\n",
    "            \n",
    "            # ä¸ºé™¤Labelå¤–çš„æ‰€æœ‰åˆ—æ·»åŠ markerå‰ç¼€ (å¦‚æœmarkerä¸ä¸ºç©º)\n",
    "            if marker:\n",
    "                rename_dict = {col: f\"{marker}_{col}\" for col in df.columns if col != 'Label'}\n",
    "                df = df.rename(columns=rename_dict)\n",
    "                print(f\"    ä¸º {file} æ·»åŠ äº†markerå‰ç¼€: {marker}\")\n",
    "            \n",
    "            dataframes.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not dataframes:\n",
    "        print(f\"âŒ æ²¡æœ‰ä¸º sam_name: {sam_name} æ‰¾åˆ°æœ‰æ•ˆæ•°æ®\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"æˆåŠŸè¯»å– {len(dataframes)} ä¸ªæ•°æ®æ–‡ä»¶\")\n",
    "    \n",
    "    # ä½¿ç”¨reduceå‡½æ•°å°†æ‰€æœ‰æ•°æ®æ¡†æŒ‰Labelåˆ—æ¨ªå‘åˆå¹¶\n",
    "    if len(dataframes) > 1:\n",
    "        final_df = reduce(\n",
    "            lambda left, right: pd.merge(left, right, on='Label', how='outer'),\n",
    "            dataframes\n",
    "        )\n",
    "        print(f\"åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆæ•°æ®æ¡†å½¢çŠ¶: {final_df.shape}\")\n",
    "    else:\n",
    "        final_df = dataframes[0]\n",
    "        print(f\"åªæœ‰ä¸€ä¸ªæ•°æ®æ¡†ï¼Œæ— éœ€åˆå¹¶ï¼Œå½¢çŠ¶: {final_df.shape}\")\n",
    "    \n",
    "    # åŒºåˆ†å¤„ç†isPositiveåˆ—å’Œå…¶ä»–åˆ—çš„ç¼ºå¤±å€¼\n",
    "    # é¦–å…ˆè·å–æ‰€æœ‰isPositiveåˆ—\n",
    "    is_positive_cols = [col for col in final_df.columns if col.endswith('_isPositive')]\n",
    "    # å…¶ä»–åˆ—ï¼ˆæ’é™¤Labelå’ŒisPositiveåˆ—ï¼‰\n",
    "    other_cols = [col for col in final_df.columns if col not in is_positive_cols and col != 'Label']\n",
    "    \n",
    "    # å¯¹isPositiveåˆ—çš„ç¼ºå¤±å€¼å¡«å……0\n",
    "    if is_positive_cols:\n",
    "        final_df[is_positive_cols] = final_df[is_positive_cols].fillna(-1)\n",
    "        print(f\"å·²å°† {len(is_positive_cols)} ä¸ªisPositiveåˆ—çš„ç¼ºå¤±å€¼å¡«å……ä¸º-1\")\n",
    "    \n",
    "    # å¯¹å…¶ä»–åˆ—çš„ç¼ºå¤±å€¼å¡«å……-1\n",
    "    if other_cols:\n",
    "        final_df[other_cols] = final_df[other_cols].fillna(-1)\n",
    "        print(f\"å·²å°† {len(other_cols)} ä¸ªå…¶ä»–åˆ—çš„ç¼ºå¤±å€¼å¡«å……ä¸º-1\")\n",
    "    \n",
    "    # æ·»åŠ hasPositiveåˆ—\n",
    "    if is_positive_cols:\n",
    "        print(f\"æ‰¾åˆ° {len(is_positive_cols)} ä¸ªisPositiveåˆ—: {is_positive_cols}\")\n",
    "        # ç¡®ä¿å‚ä¸è®¡ç®—çš„åˆ—æ˜¯æ•°å€¼ç±»å‹\n",
    "        for col in is_positive_cols:\n",
    "            if col in final_df.columns:\n",
    "                final_df[col] = pd.to_numeric(final_df[col], errors='coerce').fillna(0)  # è¿™é‡Œä¹Ÿæ”¹ä¸ºå¡«å……0\n",
    "\n",
    "        # åªè¦æœ‰ä¸€ä¸ªisPositiveåˆ—çš„å€¼ä¸º1ï¼ŒhasPositiveå°±ä¸º1ï¼Œå¦åˆ™ä¸º0\n",
    "        final_df['hasPositive'] = final_df[is_positive_cols].apply(\n",
    "            lambda row: 1 if (row == 1).any() else 0, axis=1\n",
    "        )\n",
    "        print(\"å·²è®¡ç®—hasPositiveåˆ—\")\n",
    "    else:\n",
    "        final_df['hasPositive'] = 0\n",
    "        print(\"æœªæ‰¾åˆ°isPositiveåˆ—ï¼ŒhasPositiveåˆ—è®¾ä¸ºå…¨0\")\n",
    "    \n",
    "    # åœ¨ä¿å­˜å‰åˆ é™¤æ‰€æœ‰å®Œå…¨é‡å¤çš„è¡Œ\n",
    "    original_rows = len(final_df)\n",
    "    final_df = final_df.drop_duplicates()\n",
    "    removed_rows = original_rows - len(final_df)\n",
    "    if removed_rows > 0:\n",
    "        print(f\"åˆ é™¤äº† {removed_rows} è¡Œé‡å¤æ•°æ®\")\n",
    "    \n",
    "    # ä¿å­˜åˆå¹¶åçš„æ•°æ®æ¡†\n",
    "    output_file_name = f\"{sam_name}_summary_all.csv\"\n",
    "    output_file_path = os.path.join(summary_folder, output_file_name)\n",
    "    final_df.to_csv(output_file_path, index=False)\n",
    "    print(f\"âœ… æ±‡æ€»è¡¨æ ¼å·²ä¿å­˜åˆ° {output_file_path}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"å¤„ç†å‡½æ•°å®šä¹‰å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== å¼€å§‹å¤„ç†æ‰€æœ‰sam_nameçš„æ•°æ® =====\n",
      "\n",
      "æ­£åœ¨å¤„ç† sam_name: wt\n",
      "æ‰¾åˆ° 5 ä¸ªç›¸å…³æ–‡ä»¶:\n",
      "  - wt_summary_e.csv\n",
      "  - wt_summary_b.csv\n",
      "  - wt_summary_d.csv\n",
      "  - wt_summary_c.csv\n",
      "  - wt_summary_a.csv\n",
      "    ä¸º wt_summary_e.csv æ·»åŠ äº†markerå‰ç¼€: e\n",
      "    ä¸º wt_summary_b.csv æ·»åŠ äº†markerå‰ç¼€: b\n",
      "    ä¸º wt_summary_d.csv æ·»åŠ äº†markerå‰ç¼€: d\n",
      "    ä¸º wt_summary_c.csv æ·»åŠ äº†markerå‰ç¼€: c\n",
      "    ä¸º wt_summary_a.csv æ·»åŠ äº†markerå‰ç¼€: a\n",
      "æˆåŠŸè¯»å– 5 ä¸ªæ•°æ®æ–‡ä»¶\n",
      "åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆæ•°æ®æ¡†å½¢çŠ¶: (3604, 31)\n",
      "å·²å°† 5 ä¸ªisPositiveåˆ—çš„ç¼ºå¤±å€¼å¡«å……ä¸º-1\n",
      "å·²å°† 25 ä¸ªå…¶ä»–åˆ—çš„ç¼ºå¤±å€¼å¡«å……ä¸º-1\n",
      "æ‰¾åˆ° 5 ä¸ªisPositiveåˆ—: ['e_isPositive', 'b_isPositive', 'd_isPositive', 'c_isPositive', 'a_isPositive']\n",
      "å·²è®¡ç®—hasPositiveåˆ—\n",
      "âœ… æ±‡æ€»è¡¨æ ¼å·²ä¿å­˜åˆ° yourpathway/vg_space_mapping/wt/summary\\wt_summary_all.csv\n",
      "\n",
      "æ­£åœ¨å¤„ç† sam_name: tmie\n",
      "æ‰¾åˆ° 5 ä¸ªç›¸å…³æ–‡ä»¶:\n",
      "  - tmie_summary_e.csv\n",
      "  - tmie_summary_b.csv\n",
      "  - tmie_summary_d.csv\n",
      "  - tmie_summary_c.csv\n",
      "  - tmie_summary_a.csv\n",
      "    ä¸º tmie_summary_e.csv æ·»åŠ äº†markerå‰ç¼€: e\n",
      "    ä¸º tmie_summary_b.csv æ·»åŠ äº†markerå‰ç¼€: b\n",
      "    ä¸º tmie_summary_d.csv æ·»åŠ äº†markerå‰ç¼€: d\n",
      "    ä¸º tmie_summary_c.csv æ·»åŠ äº†markerå‰ç¼€: c\n",
      "    ä¸º tmie_summary_a.csv æ·»åŠ äº†markerå‰ç¼€: a\n",
      "æˆåŠŸè¯»å– 5 ä¸ªæ•°æ®æ–‡ä»¶\n",
      "åˆå¹¶å®Œæˆï¼Œæœ€ç»ˆæ•°æ®æ¡†å½¢çŠ¶: (2090, 31)\n",
      "å·²å°† 5 ä¸ªisPositiveåˆ—çš„ç¼ºå¤±å€¼å¡«å……ä¸º-1\n",
      "å·²å°† 25 ä¸ªå…¶ä»–åˆ—çš„ç¼ºå¤±å€¼å¡«å……ä¸º-1\n",
      "æ‰¾åˆ° 5 ä¸ªisPositiveåˆ—: ['e_isPositive', 'b_isPositive', 'd_isPositive', 'c_isPositive', 'a_isPositive']\n",
      "å·²è®¡ç®—hasPositiveåˆ—\n",
      "âœ… æ±‡æ€»è¡¨æ ¼å·²ä¿å­˜åˆ° yourpathway/vg_space_mapping/wt/summary\\tmie_summary_all.csv\n",
      "\n",
      "ğŸ‰ æ‰€æœ‰ sam_name çš„æ•°æ®å¤„ç†å®Œæˆï¼\n",
      "æˆåŠŸå¤„ç†: 2/2 ä¸ªsam_name\n"
     ]
    }
   ],
   "source": [
    "# æ‰§è¡Œæ•°æ®å¤„ç†\n",
    "if len(sam_names) > 0:\n",
    "    print(\"===== å¼€å§‹å¤„ç†æ‰€æœ‰sam_nameçš„æ•°æ® =====\")\n",
    "    \n",
    "    success_count = 0\n",
    "    for sam_name in sam_names:\n",
    "        if process_sam_name(sam_name, summary_folder):\n",
    "            success_count += 1\n",
    "    \n",
    "    print(f\"\\nğŸ‰ æ‰€æœ‰ sam_name çš„æ•°æ®å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"æˆåŠŸå¤„ç†: {success_count}/{len(sam_names)} ä¸ªsam_name\")\n",
    "else:\n",
    "    print(\"âŒ æ²¡æœ‰æ‰¾åˆ°sam_nameï¼Œæ— æ³•è¿›è¡Œå¤„ç†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶ =====\n",
      "æ‰¾åˆ° 2 ä¸ªæ±‡æ€»æ–‡ä»¶:\n",
      "  - tmie_summary_all.csv (933631 bytes)\n",
      "    å½¢çŠ¶: (2090, 32), åˆ—æ•°: 32\n",
      "    åˆ—å: ['Label', 'e_pos_X', 'e_pos_Y', 'e_warpedROIvar1', 'e_warpedROIvar2']...\n",
      "  - wt_summary_all.csv (1581245 bytes)\n",
      "    å½¢çŠ¶: (3604, 32), åˆ—æ•°: 32\n",
      "    åˆ—å: ['Label', 'e_pos_X', 'e_pos_Y', 'e_warpedROIvar1', 'e_warpedROIvar2']...\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶\n",
    "print(\"\\n===== æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶ =====\")\n",
    "if os.path.exists(summary_folder):\n",
    "    all_files = [f for f in os.listdir(summary_folder) if f.endswith('_all.csv')]\n",
    "    if all_files:\n",
    "        print(f\"æ‰¾åˆ° {len(all_files)} ä¸ªæ±‡æ€»æ–‡ä»¶:\")\n",
    "        for file in all_files:\n",
    "            file_path = os.path.join(summary_folder, file)\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            print(f\"  - {file} ({file_size} bytes)\")\n",
    "            \n",
    "            # æ˜¾ç¤ºæ–‡ä»¶å†…å®¹é¢„è§ˆ\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                print(f\"    å½¢çŠ¶: {df.shape}, åˆ—æ•°: {len(df.columns)}\")\n",
    "                print(f\"    åˆ—å: {list(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}\")\n",
    "            except Exception as e:\n",
    "                print(f\"    æ— æ³•è¯»å–æ–‡ä»¶å†…å®¹: {e}\")\n",
    "    else:\n",
    "        print(\"æœªæ‰¾åˆ°ä»»ä½•æ±‡æ€»æ–‡ä»¶\")\n",
    "else:\n",
    "    print(f\"æ±‡æ€»æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {summary_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ•°æ®å¤„ç†å®Œæˆï¼\n",
    "\n",
    "æ‰€æœ‰sam_nameçš„æ•°æ®å·²æˆåŠŸå¤„ç†å¹¶åˆå¹¶ã€‚\n",
    "\n",
    "**å¤„ç†ç»“æœ**:\n",
    "- æ¯ä¸ªsam_nameç”Ÿæˆäº†ä¸€ä¸ª `{sam_name}_summary_all.csv` æ–‡ä»¶\n",
    "- æ‰€æœ‰markeræ•°æ®æŒ‰Labelåˆ—åˆå¹¶\n",
    "- æ·»åŠ äº†hasPositiveåˆ—æ ‡è¯†é˜³æ€§ç»“æœ\n",
    "- é‡å¤æ•°æ®å·²è‡ªåŠ¨æ¸…ç†\n",
    "\n",
    "**ä¸‹ä¸€æ­¥**: å¯ä»¥ä½¿ç”¨ç”Ÿæˆçš„æ–‡ä»¶è¿›è¡Œåç»­åˆ†ææˆ–å¯è§†åŒ–ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
